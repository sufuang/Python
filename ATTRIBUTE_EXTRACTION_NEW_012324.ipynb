{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "47491761-4c9b-4724-9317-892d8868679e",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Versions of libraries used\n",
    "numpy==1.24.3\n",
    "pandas==1.3.4\n",
    "rapidfuzz==3.6.1\n",
    "ipywidgets==8.1.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f10fa2b5-df18-41a3-8e64-45036a501efe",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Output File path: \n",
    "/dbfs/FileStore/tables/NORMALIZED_ATTRIBUTE_OUTPUTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a4826edf-cf3a-484f-889c-b497892dc796",
     "showTitle": true,
     "title": "Run to set up the environment and load up the code"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[43mNote: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages.\u001B[0m\nRequirement already satisfied: pip in /local_disk0/.ephemeral_nfs/envs/pythonEnv-505d017e-d096-4c2b-8cc4-8f9b8214ab08/lib/python3.10/site-packages (22.3.1)\nCollecting pip\n  Downloading pip-23.3.2-py3-none-any.whl (2.1 MB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2.1/2.1 MB 10.9 MB/s eta 0:00:00\nInstalling collected packages: pip\n  Attempting uninstall: pip\n    Found existing installation: pip 22.3.1\n    Uninstalling pip-22.3.1:\n      Successfully uninstalled pip-22.3.1\nSuccessfully installed pip-23.3.2\n\u001B[43mNote: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages.\u001B[0m\n\u001B[43mNote: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages.\u001B[0m\nCollecting ipywidgets==8.1.1\n  Downloading ipywidgets-8.1.1-py3-none-any.whl.metadata (2.4 kB)\nCollecting comm>=0.1.3 (from ipywidgets==8.1.1)\n  Downloading comm-0.2.1-py3-none-any.whl.metadata (3.7 kB)\nRequirement already satisfied: ipython>=6.1.0 in /databricks/python3/lib/python3.10/site-packages (from ipywidgets==8.1.1) (8.14.0)\nRequirement already satisfied: traitlets>=4.3.1 in /databricks/python3/lib/python3.10/site-packages (from ipywidgets==8.1.1) (5.7.1)\nCollecting widgetsnbextension~=4.0.9 (from ipywidgets==8.1.1)\n  Downloading widgetsnbextension-4.0.9-py3-none-any.whl.metadata (1.6 kB)\nCollecting jupyterlab-widgets~=3.0.9 (from ipywidgets==8.1.1)\n  Downloading jupyterlab_widgets-3.0.9-py3-none-any.whl.metadata (4.1 kB)\nRequirement already satisfied: backcall in /databricks/python3/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets==8.1.1) (0.2.0)\nRequirement already satisfied: decorator in /databricks/python3/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets==8.1.1) (5.1.1)\nRequirement already satisfied: jedi>=0.16 in /databricks/python3/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets==8.1.1) (0.18.1)\nRequirement already satisfied: matplotlib-inline in /databricks/python3/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets==8.1.1) (0.1.6)\nRequirement already satisfied: pickleshare in /databricks/python3/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets==8.1.1) (0.7.5)\nRequirement already satisfied: prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30 in /databricks/python3/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets==8.1.1) (3.0.36)\nRequirement already satisfied: pygments>=2.4.0 in /databricks/python3/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets==8.1.1) (2.11.2)\nRequirement already satisfied: stack-data in /databricks/python3/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets==8.1.1) (0.2.0)\nRequirement already satisfied: pexpect>4.3 in /databricks/python3/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets==8.1.1) (4.8.0)\nRequirement already satisfied: parso<0.9.0,>=0.8.0 in /databricks/python3/lib/python3.10/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets==8.1.1) (0.8.3)\nRequirement already satisfied: ptyprocess>=0.5 in /databricks/python3/lib/python3.10/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets==8.1.1) (0.7.0)\nRequirement already satisfied: wcwidth in /databricks/python3/lib/python3.10/site-packages (from prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30->ipython>=6.1.0->ipywidgets==8.1.1) (0.2.5)\nRequirement already satisfied: executing in /databricks/python3/lib/python3.10/site-packages (from stack-data->ipython>=6.1.0->ipywidgets==8.1.1) (0.8.3)\nRequirement already satisfied: asttokens in /databricks/python3/lib/python3.10/site-packages (from stack-data->ipython>=6.1.0->ipywidgets==8.1.1) (2.0.5)\nRequirement already satisfied: pure-eval in /databricks/python3/lib/python3.10/site-packages (from stack-data->ipython>=6.1.0->ipywidgets==8.1.1) (0.2.2)\nRequirement already satisfied: six in /usr/lib/python3/dist-packages (from asttokens->stack-data->ipython>=6.1.0->ipywidgets==8.1.1) (1.16.0)\nDownloading ipywidgets-8.1.1-py3-none-any.whl (139 kB)\n\u001B[?25l   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m0.0/139.4 kB\u001B[0m \u001B[31m?\u001B[0m eta \u001B[36m-:--:--\u001B[0m\n\u001B[2K   \u001B[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[90m╺\u001B[0m\u001B[90m━\u001B[0m \u001B[32m133.1/139.4 kB\u001B[0m \u001B[31m6.4 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\n\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m139.4/139.4 kB\u001B[0m \u001B[31m2.1 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n\u001B[?25hDownloading comm-0.2.1-py3-none-any.whl (7.2 kB)\nDownloading jupyterlab_widgets-3.0.9-py3-none-any.whl (214 kB)\n\u001B[?25l   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m0.0/214.9 kB\u001B[0m \u001B[31m?\u001B[0m eta \u001B[36m-:--:--\u001B[0m\n\u001B[2K   \u001B[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[90m╺\u001B[0m\u001B[90m━\u001B[0m \u001B[32m204.8/214.9 kB\u001B[0m \u001B[31m11.8 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\n\u001B[2K   \u001B[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[90m╺\u001B[0m\u001B[90m━\u001B[0m \u001B[32m204.8/214.9 kB\u001B[0m \u001B[31m11.8 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\n\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m214.9/214.9 kB\u001B[0m \u001B[31m2.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n\u001B[?25hDownloading widgetsnbextension-4.0.9-py3-none-any.whl (2.3 MB)\n\u001B[?25l   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m0.0/2.3 MB\u001B[0m \u001B[31m?\u001B[0m eta \u001B[36m-:--:--\u001B[0m\n\u001B[2K   \u001B[91m━━━━━━━━\u001B[0m\u001B[90m╺\u001B[0m\u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m0.5/2.3 MB\u001B[0m \u001B[31m14.2 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\n\u001B[2K   \u001B[91m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[91m╸\u001B[0m\u001B[90m━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m1.1/2.3 MB\u001B[0m \u001B[31m16.2 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\n\u001B[2K   \u001B[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[91m╸\u001B[0m\u001B[90m━━━━━\u001B[0m \u001B[32m2.0/2.3 MB\u001B[0m \u001B[31m19.2 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\n\u001B[2K   \u001B[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[91m╸\u001B[0m \u001B[32m2.3/2.3 MB\u001B[0m \u001B[31m20.0 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\n\u001B[2K   \u001B[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[91m╸\u001B[0m \u001B[32m2.3/2.3 MB\u001B[0m \u001B[31m20.0 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\n\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m2.3/2.3 MB\u001B[0m \u001B[31m12.7 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n\u001B[?25hInstalling collected packages: widgetsnbextension, jupyterlab-widgets, comm, ipywidgets\n  Attempting uninstall: widgetsnbextension\n    Found existing installation: widgetsnbextension 3.6.1\n    Not uninstalling widgetsnbextension at /databricks/python3/lib/python3.10/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-505d017e-d096-4c2b-8cc4-8f9b8214ab08\n    Can't uninstall 'widgetsnbextension'. No files were found to uninstall.\n  Attempting uninstall: jupyterlab-widgets\n    Found existing installation: jupyterlab-widgets 1.0.0\n    Not uninstalling jupyterlab-widgets at /databricks/python3/lib/python3.10/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-505d017e-d096-4c2b-8cc4-8f9b8214ab08\n    Can't uninstall 'jupyterlab-widgets'. No files were found to uninstall.\n  Attempting uninstall: comm\n    Found existing installation: comm 0.1.2\n    Not uninstalling comm at /databricks/python3/lib/python3.10/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-505d017e-d096-4c2b-8cc4-8f9b8214ab08\n    Can't uninstall 'comm'. No files were found to uninstall.\n  Attempting uninstall: ipywidgets\n    Found existing installation: ipywidgets 7.7.2\n    Not uninstalling ipywidgets at /databricks/python3/lib/python3.10/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-505d017e-d096-4c2b-8cc4-8f9b8214ab08\n    Can't uninstall 'ipywidgets'. No files were found to uninstall.\nSuccessfully installed comm-0.2.1 ipywidgets-8.1.1 jupyterlab-widgets-3.0.9 widgetsnbextension-4.0.9\n\u001B[43mNote: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages.\u001B[0m\n\u001B[43mNote: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages.\u001B[0m\nRequirement already satisfied: numpy==1.24.3 in /local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.10/site-packages (1.24.3)\n\u001B[43mNote: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages.\u001B[0m\n\u001B[43mNote: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages.\u001B[0m\nRequirement already satisfied: rapidfuzz==3.6.1 in /local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.10/site-packages (3.6.1)\n\u001B[43mNote: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages.\u001B[0m\n\u001B[43mNote: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages.\u001B[0m\nRequirement already satisfied: pandas==1.3.4 in /local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.10/site-packages (1.3.4)\nRequirement already satisfied: python-dateutil>=2.7.3 in /databricks/python3/lib/python3.10/site-packages (from pandas==1.3.4) (2.8.2)\nRequirement already satisfied: pytz>=2017.3 in /local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.10/site-packages (from pandas==1.3.4) (2021.3)\nRequirement already satisfied: numpy>=1.21.0 in /local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.10/site-packages (from pandas==1.3.4) (1.24.3)\nRequirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.7.3->pandas==1.3.4) (1.16.0)\n\u001B[43mNote: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages.\u001B[0m\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "\"\\n### Select an Attribute\\nprint('Choose the latest input file to run')\\ninputs_dir = '/dbfs/FileStore/tables/NORMALIZED_ATTRIBUTE_INPUTS/'\\nInputList =  os.listdir(inputs_dir)\\ninput_w = widgets.Dropdown(\\n    options=InputList,\\n    value=InputList[0],\\n    description='Attribute:',\\n    disabled=False,\\n)\\ndisplay(input_w)\""
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pip install -U pip\n",
    "%pip install -U ipywidgets==8.1.1\n",
    "%pip install -U numpy==1.24.3\n",
    "%pip install -U rapidfuzz==3.6.1\n",
    "%pip install -U pandas==1.3.4\n",
    "\n",
    "import pandas as pd, numpy as np\n",
    "import os\n",
    "import io\n",
    "import json\n",
    "import datetime as dt\n",
    "from rapidfuzz import process, fuzz,utils\n",
    "from ipywidgets import widgets\n",
    "import datetime as dt\n",
    "\n",
    "np.set_printoptions(threshold=np.inf)\n",
    "pd.set_option('chained_assignment',None)\n",
    "### List of departments applicable for each attribute type\n",
    "attr_dpt_map = {'Color':['Kitchen & Dining', 'Home Décor' ,'Floral'],\\\n",
    "                'Flavor': ['Pantry','Beverages','Frozen Foods','Candy'],\\\n",
    "                'Scent':['Cleaning and Household','Beauty','Personal Care']}\n",
    "\n",
    "attb_dpt_combos = []\n",
    "for attb in attr_dpt_map.keys():\n",
    "    for i in attr_dpt_map[attb]:\n",
    "        attb_dpt_combos.append((attb,i))\n",
    "\n",
    "### Substitutions to be made within the input text before performing the fuzzy match\n",
    "replacements = {          \n",
    " ',': ' ',\n",
    " '/': ' ',\n",
    " '>':' ',\n",
    "'<': ' ',\n",
    "'COFFEE TABLE':'TABLE'}\n",
    "\n",
    "def remove_substrings(flav_list):\n",
    "    flav_df = pd.DataFrame(flav_list, columns=['Sentence', 'Scores'])\n",
    "    flav_df['Word Length'] = flav_df.Sentence.apply(lambda x: len(x.split(' ')))\n",
    "    flav_df.sort_values('Word Length', inplace= True)\n",
    "    flav_df.reset_index(drop = True, inplace= True)\n",
    "    filtered_flav_df = flav_df[flav_df.Scores==100]\n",
    "    if len(filtered_flav_df.index)==0:\n",
    "        return flav_df.Sentence.tolist()\n",
    "    if len(filtered_flav_df.index)==1:\n",
    "        return filtered_flav_df.Sentence.tolist()\n",
    "    filtered_flav_df['Drop'] = ''\n",
    "    for x in range(len(filtered_flav_df)):\n",
    "        str_1 = filtered_flav_df.Sentence.iloc[x]\n",
    "        if x==len(filtered_flav_df):\n",
    "            break\n",
    "        for sent in filtered_flav_df.Sentence.iloc[x+1:]:\n",
    "            if str_1 in sent:\n",
    "                filtered_flav_df.Drop.iloc[x] = 'Yes'\n",
    "                break\n",
    "            if len(flav_df) < 2:\n",
    "                break\n",
    "    return filtered_flav_df[filtered_flav_df.Drop != 'Yes'].Sentence.tolist()\n",
    "\n",
    "# Match using 'token set ratio' with threshold\n",
    "def attribute_fetch(item, color_list_org, subs,cutoff = 85):\n",
    "    color_list = color_list_org \n",
    "    color_no_spaces = [ i for i in color_list_org if not '' in i]\n",
    "    color_with_spaces = [ i for i in color_list_org if i not in color_no_spaces]\n",
    "    abbrev_maps = {}\n",
    "    for i in color_no_spaces:\n",
    "        for j in color_with_spaces:\n",
    "            if j.replace(' ','') == i:\n",
    "                abbrev_maps[i] = j\n",
    "    matched = process.extract(item, color_list, score_cutoff= cutoff, scorer = fuzz.token_set_ratio, processor=utils.default_process, limit= 7)\n",
    "    color_shortlist = [i[0] for i in matched]\n",
    "    matched = [i for i in matched if i[0] in color_shortlist]\n",
    "    if len(color_shortlist) > 0:\n",
    "        max_score = matched[0][1]\n",
    "        final_match = [i for i in matched if i[1]== max_score]\n",
    "        match_list = [i[0] for i in final_match]\n",
    "        match_list = [abbrev_maps[i] if i in abbrev_maps.keys() else i for i in match_list]\n",
    "        match_list = remove_substrings(zip(match_list, [100]*len(match_list)))\n",
    "        match_list = [subs[i] if i in subs.keys() else i for i in match_list]        \n",
    "        rematched = process.extract(item, match_list,  scorer = fuzz.partial_ratio, processor=utils.default_process, limit = 5)\n",
    "        re_max_score = rematched[0][1]\n",
    "        final_rematch = [ i for i in rematched if i[1]== re_max_score]\n",
    "        match_list =  remove_substrings([i[0:2] for i in final_rematch])\n",
    "        match_list_ordered =[]\n",
    "        for word in item.split(' '): # Ordering scents according to their appearance in the description text\n",
    "            for color_token in match_list:\n",
    "                if word in color_token:\n",
    "                    match_list_ordered.append(color_token)\n",
    "                    continue\n",
    "        if len(match_list_ordered) > 0:\n",
    "            match_list = pd.Series(match_list_ordered).drop_duplicates().tolist()\n",
    "        else:\n",
    "            match_list = pd.Series(match_list).drop_duplicates().tolist()\n",
    "        matched = ';'.join(list(pd.Series(match_list)))\n",
    "    else: \n",
    "        matched = 'OTHER'\n",
    "    return matched\n",
    "\n",
    "'''\n",
    "### Select an Attribute\n",
    "print('Choose the latest input file to run')\n",
    "inputs_dir = '/dbfs/FileStore/tables/NORMALIZED_ATTRIBUTE_INPUTS/'\n",
    "InputList =  os.listdir(inputs_dir)\n",
    "input_w = widgets.Dropdown(\n",
    "    options=InputList,\n",
    "    value=InputList[0],\n",
    "    description='Attribute:',\n",
    "    disabled=False,\n",
    ")\n",
    "display(input_w)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1345776c-fde7-4cb4-8af7-088a082bdd56",
     "showTitle": true,
     "title": "Run the latest input file to generate the output (This might take a few minutes)"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the latest input file: /dbfs/FileStore/tables/NORMALIZED_ATTRIBUTE_INPUTS/SampleInputWeekly_122424-1.csv\nCompleted loading up configs.\nColor Kitchen & Dining\nTotal input items: [ 476 x 5 ]\nCompleted loading up configs.\nColor Home_Decor_Rugs\nTotal input items: [ 28 x 5 ]\nCompleted loading up configs.\nColor Home_Decor_NoRugs\nTotal input items: [ 596 x 5 ]\nCompleted loading up configs.\nColor Floral\nTotal input items: [ 193 x 5 ]\nCompleted loading up configs.\nFlavor Pantry\nTotal input items: [ 4807 x 5 ]\nCompleted loading up configs.\nFlavor Beverages\nTotal input items: [ 1483 x 5 ]\nCompleted loading up configs.\nFlavor Ice Cream\nTotal input items: [ 248 x 5 ]\nCompleted loading up configs.\nFlavor Candy\nTotal input items: [ 1403 x 5 ]\nCompleted loading up configs.\nScent Cleaning and Household\nTotal input items: [ 934 x 5 ]\nCompleted loading up configs.\nScent Beauty\nTotal input items: [ 1641 x 5 ]\nCompleted loading up configs.\nPersonal Care\nScent Personal Care\nTotal input items: [ 1766 x 5 ]\nGenerating the output and saving the results...\nDone... DBFS Path:  /dbfs/FileStore/tables/NORMALIZED_ATTRIBUTE_OUTPUTS/ NormalIzed_Attributes_01252024_.csv\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06a02df6f315464eba67a2d45881b761",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value='<html>\\n<head>\\n<meta name=\"viewport\" content=\"width=device-width, initial-scale=1\">\\n</head>\\n<bo…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\nIf the above link doesn't work, try pasting this URL into your browser.\nhttp://adb-4812933386228410.10.azuredatabricks.net/files/tables/NORMALIZED_ATTRIBUTE_OUTPUTS/NormalIzed_Attributes_01252024_.csv\n"
     ]
    }
   ],
   "source": [
    "def newest(path): ##Find the newest file in the directory\n",
    "    files = os.listdir(path)\n",
    "    paths = [os.path.join(path, basename) for basename in files]\n",
    "    return max(paths, key=os.path.getctime)\n",
    "\n",
    "input_path = '/dbfs/FileStore/tables/NORMALIZED_ATTRIBUTE_INPUTS/'\n",
    "newest_file = newest(input_path)\n",
    "print('Loading the latest input file:',newest_file)\n",
    "input_df = pd.read_csv(newest_file)\n",
    "\n",
    "attb_dpt_inputs = {}\n",
    "for i in attb_dpt_combos:\n",
    "    attb = i[0]\n",
    "    dpt = i[1]\n",
    "    input_dpt = input_df[input_df.DEPARTMENT == dpt]\n",
    "    if dpt == 'Home Décor':\n",
    "        rugs = input_dpt[input_dpt.COMMODITY == 'Rugs']\n",
    "        dpt = 'Home_Decor_Rugs'\n",
    "        attb_dpt_inputs[(attb, dpt)] = rugs\n",
    "        no_rugs = input_dpt[input_dpt.COMMODITY != 'Rugs']\n",
    "        dpt = 'Home_Decor_NoRugs'\n",
    "        attb_dpt_inputs[(attb, dpt)] =  no_rugs\n",
    "    elif dpt == 'Frozen Foods':\n",
    "        dpt = 'Ice Cream'\n",
    "        attb_dpt_inputs[(attb, dpt)] =  input_dpt\n",
    "    else: attb_dpt_inputs[(attb, dpt)] = input_dpt\n",
    "\n",
    "outputs = []\n",
    "for keys in attb_dpt_inputs.keys():\n",
    "    attrib = keys[0]\n",
    "    select_dpt = keys[1]\n",
    "    items = attb_dpt_inputs[keys]\n",
    "    configs_dir = '/dbfs/FileStore/tables/DATA_SCIENCE/FuzzyConfigs/'\n",
    "    configsList =  os.listdir(configs_dir)\n",
    "    configfile = [i for i in configsList if ((select_dpt.replace(' ','') in i) | (select_dpt.replace(' ', '').replace('&','and') in i) ) and attrib.upper() in i][0]\n",
    "\n",
    "    ### Load configs\n",
    "    with open(configs_dir + configfile, \"r\") as read_file:\n",
    "        configs = json.load(read_file)\n",
    "    print('Completed loading up configs.')\n",
    "\n",
    "    ### Extract the configs\n",
    "    attb_list = configs['Normalized_list']\n",
    "    attb_subs = configs['Substitutions']\n",
    "\n",
    "    ########################################################################################################################\n",
    "\n",
    "    def remove_scentlist(itm):\n",
    "        for iter in itm:\n",
    "            if iter in attb_list: attb_list.remove(iter)\n",
    "\n",
    "    if select_dpt == 'Personal Care': \n",
    "        print(select_dpt)\n",
    "        remove_scentlist(['RELAX','CALMING','CALM','OATMEAL','REGULAR','HERBAL','BERRY','CLASSIC','SEA SALT'])\n",
    "    remove_scentlist(['SUGAR','SWEET','SALT', 'CHOCO', 'WATERMELON'])\n",
    "    attb_list += ['PNUT BUTTER', 'BBQ', 'PBUTTER', 'PMPKIN', 'SANDALWOOD', 'CAFFEINE', 'CAFFEINE FREE', 'CAFFEINATED', 'MELON']\n",
    "\n",
    "    attb_subs.update({'PNUT BUTTER':'PEANUT BUTTER', 'BBQ':'BARBECUE', 'PBUTTER':'PEANUT BUTTER', 'PMPKIN':'PUMPKIN', 'CAFFEINE':'COFFEE', 'CAFFEINE FREE':'', 'CAFFEINATED':'COFFEE', 'STRBRY':'STRAWBERRY', 'GOLD':''})\n",
    "\n",
    "    # Generate Results\n",
    "    print(attrib, select_dpt)\n",
    "    print(f\"Total input items: [ {len(items.index)} x {len(items.columns)} ]\")\n",
    "    items['Normalized_'+attrib] = items.DESCRIPTION.replace(replacements, regex = True).apply(lambda x: attribute_fetch(x, color_list_org=attb_list, subs=attb_subs))\n",
    "    outputs.append(items)\n",
    "\n",
    "output_df = pd.concat(outputs)\n",
    "# Save results \n",
    "today = dt.datetime.today().strftime(\"%m%d%Y\")\n",
    "#input_file = list(upload_w.value.values())[0]['metadata']['name']\n",
    "#input_file = input_file.replace(' ','_').replace('&','_')\n",
    "output_path = '/dbfs/FileStore/tables/NORMALIZED_ATTRIBUTE_OUTPUTS/'\n",
    "outfile = 'NormalIzed_Attributes_' + today +'_.csv'\n",
    "\n",
    "items = output_df.copy()\n",
    "print('Generating the output and saving the results...')\n",
    "for i in range(len(items['Normalized_' + attrib].tolist())):\n",
    "    if items['Normalized_' + attrib].fillna('').iloc[i].find('UNSCENTED') > -1:\n",
    "        items.at[i, 'Normalized_' + attrib] = 'UNSCENTED'\n",
    "    if items['Normalized_' + attrib].fillna('').iloc[i].find('FRAGRANCE FREE') > -1:\n",
    "        items.at[i, 'Normalized_' + attrib] = 'FRAGRANCE FREE'\n",
    "\n",
    "    if items['DESCRIPTION'].iloc[i].upper().find('GOLD BOND') > -1:\n",
    "        items.at[i, 'Normalized_' + attrib] = items['Normalized_' + attrib].iloc[i].replace(';GOLD', '')\n",
    "        items.at[i, 'Normalized_' + attrib] = items['Normalized_' + attrib].iloc[i].replace('GOLD;', '')\n",
    "\n",
    "    if items['Normalized_' + attrib].fillna('').iloc[i].find(';SCENTED') > -1:\n",
    "        items.at[i, 'Normalized_' + attrib] = items['Normalized_' + attrib].iloc[i].replace(';SCENTED', '')\n",
    "    if items['Normalized_' + attrib].fillna('').iloc[i].find('SCENTED;') > -1:\n",
    "        items.at[i, 'Normalized_' + attrib] = items['Normalized_' + attrib].iloc[i].replace('SCENTED;', '')\n",
    "    if items['Normalized_' + attrib].fillna('').iloc[i].find('ORIGINAL;') > -1:\n",
    "        items.at[i, 'Normalized_' + attrib] = items['Normalized_' + attrib].iloc[i].replace('ORIGINAL;', '')\n",
    "    if items['Normalized_' + attrib].fillna('').iloc[i].find(';ORIGINAL') > -1:\n",
    "        items.at[i, 'Normalized_' + attrib] = items['Normalized_' + attrib].iloc[i].replace(';ORIGINAL', '')\n",
    "    if items['Normalized_' + attrib].fillna('').iloc[i].find('CAFFEINE FREE') > -1:\n",
    "        items.at[i, 'Normalized_' + attrib] = items['Normalized_' + attrib].iloc[i].replace('COFFEE', 'OTHER')\n",
    "    if items['Normalized_' + attrib].fillna('').iloc[i]=='':\n",
    "        items.at[i, 'Normalized_' + attrib] = \"OTHER\"\n",
    "for attrib in ['Color','Flavor','Scent']:\n",
    "    items = items.rename(columns={'Normalized_'+attrib : 'Kroger Derived Normalized '+attrib})\n",
    "items['GTIN'] = items.GTIN.astype(int).astype(str).apply(lambda x: (14- len(x))*'0'+x)\n",
    "items['Kroger Derived Normalized Diet Type'] = np.nan\n",
    "\n",
    "cols2keep = ['GTIN','Kroger Derived Normalized Flavor', 'Kroger Derived Normalized Scent','Kroger Derived Normalized Color','Kroger Derived Normalized Diet Type']\n",
    "items[cols2keep].to_csv(output_path+ outfile, index = None , sep = '|')\n",
    "print(\"Done... DBFS Path:  /dbfs/FileStore/tables/NORMALIZED_ATTRIBUTE_OUTPUTS/\", outfile)\n",
    "\n",
    "#########################################################################################\n",
    "\n",
    "from ipywidgets import HTML\n",
    "from IPython.display import display\n",
    "import base64\n",
    "result = (\"http://adb-4812933386228410.10.azuredatabricks.net/files/tables/NORMALIZED_ATTRIBUTE_OUTPUTS/\" + outfile)\n",
    "\n",
    "filename = outfile\n",
    "b64 = base64.b64encode(result.encode())\n",
    "payload = b64.decode()\n",
    "\n",
    "html_buttons = '''<html>\n",
    "<head>\n",
    "<meta name=\"viewport\" content=\"width=device-width, initial-scale=1\">\n",
    "</head>\n",
    "<body>\n",
    "<a download=\"{filename}\" href=\"'''+ result +'''\" download>\n",
    "<button class=\"p-Widget jupyter-widgets jupyter-button widget-button mod-info\"><b>Download File</b></button>\n",
    "</a>\n",
    "</body>\n",
    "</html>\n",
    "'''\n",
    "\n",
    "html_button = html_buttons.format(payload=payload,filename=filename)\n",
    "display(HTML(html_button))\n",
    "\n",
    "print(\"\\nIf the above link doesn't work, try pasting this URL into your browser.\\n\" + result)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "ATTRIBUTE_EXTRACTION_NEW_012324",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
