{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "eb65a2cf-9222-4bb0-bc5e-2e2d119e3a05",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python interpreter will be restarted.\n",
      "Requirement already satisfied: packaging in /local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages (21.2)\n",
      "Collecting packaging\n",
      "  Downloading packaging-23.1-py3-none-any.whl (48 kB)\n",
      "Installing collected packages: packaging\n",
      "  Attempting uninstall: packaging\n",
      "    Found existing installation: packaging 21.2\n",
      "    Not uninstalling packaging at /local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-754c325a-55a5-415d-94e1-cd5506bc9c9f\n",
      "    Can't uninstall 'packaging'. No files were found to uninstall.\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "notebook 0.0.0 requires numpy==1.21.3, but you have numpy 1.24.3 which is incompatible.\n",
      "notebook 0.0.0 requires packaging==21.2, but you have packaging 23.1 which is incompatible.\n",
      "widgetsnbextension 3.6.1 requires notebook>=4.4.1, but you have notebook 0.0.0 which is incompatible.\n",
      "Successfully installed packaging-23.1\n",
      "Python interpreter will be restarted.\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade packaging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9b83b1d5-575b-4c6f-826b-6cdb03c38f39",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package                           Version\n",
      "--------------------------------- --------------------\n",
      "absl-py                           1.4.0\n",
      "aiohttp                           3.8.5\n",
      "aiosignal                         1.3.1\n",
      "alembic                           1.11.3\n",
      "argon2-cffi                       21.3.0\n",
      "argon2-cffi-bindings              21.2.0\n",
      "asttokens                         2.0.5\n",
      "astunparse                        1.6.3\n",
      "async-timeout                     4.0.3\n",
      "attrs                             21.2.0\n",
      "azure-common                      1.1.28\n",
      "azure-core                        1.29.2\n",
      "azure-eventhub                    5.11.4\n",
      "azure-identity                    1.14.0\n",
      "azure-mgmt-core                   1.4.0\n",
      "azure-mgmt-datafactory            3.1.0\n",
      "azure-mgmt-subscription           3.1.1\n",
      "backcall                          0.2.0\n",
      "backports.entry-points-selectable 1.2.0\n",
      "beautifulsoup4                    4.11.1\n",
      "bertopic                          0.15.0\n",
      "black                             22.3.0\n",
      "bleach                            4.1.0\n",
      "blinker                           1.6.2\n",
      "boto3                             1.21.32\n",
      "botocore                          1.24.32\n",
      "cachetools                        5.3.1\n",
      "certifi                           2021.10.8\n",
      "cffi                              1.15.0\n",
      "chardet                           4.0.0\n",
      "charset-normalizer                2.0.4\n",
      "click                             8.1.7\n",
      "cloudpickle                       2.2.1\n",
      "cmake                             3.27.2\n",
      "cryptography                      3.4.8\n",
      "cycler                            0.11.0\n",
      "Cython                            0.29.28\n",
      "databricks-cli                    0.14.3\n",
      "databricks-connect                11.3.10\n",
      "dbus-python                       1.2.16\n",
      "dbx                               0.2.0\n",
      "debugpy                           1.5.1\n",
      "decorator                         5.1.1\n",
      "defusedxml                        0.7.1\n",
      "distlib                           0.3.6\n",
      "distro                            1.4.0\n",
      "distro-info                       0.23ubuntu1\n",
      "docker                            6.1.3\n",
      "docstring-to-markdown             0.11\n",
      "entrypoints                       0.4\n",
      "executing                         0.8.3\n",
      "facets-overview                   1.0.0\n",
      "fastjsonschema                    2.16.2\n",
      "filelock                          3.9.0\n",
      "findspark                         2.0.1\n",
      "Flask                             2.3.2\n",
      "flatbuffers                       23.5.26\n",
      "fonttools                         4.25.0\n",
      "frozenlist                        1.4.0\n",
      "fsspec                            2023.6.0\n",
      "gast                              0.4.0\n",
      "gensim                            4.3.1\n",
      "gitdb                             4.0.10\n",
      "GitPython                         3.1.32\n",
      "google-auth                       2.22.0\n",
      "google-auth-oauthlib              1.0.0\n",
      "google-pasta                      0.2.0\n",
      "greenlet                          2.0.2\n",
      "grpcio                            1.57.0\n",
      "gunicorn                          21.2.0\n",
      "h5py                              3.9.0\n",
      "hdbscan                           0.8.33\n",
      "huggingface-hub                   0.16.4\n",
      "idna                              3.3\n",
      "importlib-metadata                6.8.0\n",
      "iniconfig                         1.1.1\n",
      "ipykernel                         6.15.3\n",
      "ipython                           8.5.0\n",
      "ipython-genutils                  0.2.0\n",
      "ipywidgets                        7.7.2\n",
      "isodate                           0.6.1\n",
      "itsdangerous                      2.1.2\n",
      "jedi                              0.18.1\n",
      "Jinja2                            3.1.2\n",
      "jmespath                          0.10.0\n",
      "joblib                            1.1.1\n",
      "jsonschema                        4.4.0\n",
      "jupyter-client                    6.1.12\n",
      "jupyter_core                      4.11.2\n",
      "jupyterlab-pygments               0.1.2\n",
      "jupyterlab-widgets                1.0.0\n",
      "keras                             2.13.1\n",
      "kiwisolver                        1.3.2\n",
      "libclang                          16.0.6\n",
      "lit                               16.0.6\n",
      "llvmlite                          0.40.1\n",
      "Mako                              1.2.4\n",
      "Markdown                          3.4.4\n",
      "MarkupSafe                        2.1.3\n",
      "matplotlib                        3.5.1\n",
      "matplotlib-inline                 0.1.2\n",
      "mccabe                            0.7.0\n",
      "mistune                           0.8.4\n",
      "mlflow                            2.6.0\n",
      "mpmath                            1.3.0\n",
      "msal                              1.23.0\n",
      "msal-extensions                   1.0.0\n",
      "msrest                            0.7.1\n",
      "multidict                         6.0.4\n",
      "mypy-extensions                   0.4.3\n",
      "nbclient                          0.5.13\n",
      "nbconvert                         6.4.4\n",
      "nbformat                          5.3.0\n",
      "nest-asyncio                      1.5.5\n",
      "networkx                          3.1\n",
      "nltk                              3.8.1\n",
      "nodeenv                           1.7.0\n",
      "notebook                          0.0.0\n",
      "numba                             0.57.1\n",
      "numpy                             1.24.3\n",
      "nvidia-cublas-cu11                11.10.3.66\n",
      "nvidia-cuda-cupti-cu11            11.7.101\n",
      "nvidia-cuda-nvrtc-cu11            11.7.99\n",
      "nvidia-cuda-runtime-cu11          11.7.99\n",
      "nvidia-cudnn-cu11                 8.5.0.96\n",
      "nvidia-cufft-cu11                 10.9.0.58\n",
      "nvidia-curand-cu11                10.2.10.91\n",
      "nvidia-cusolver-cu11              11.4.0.1\n",
      "nvidia-cusparse-cu11              11.7.4.91\n",
      "nvidia-nccl-cu11                  2.14.3\n",
      "nvidia-nvtx-cu11                  11.7.91\n",
      "oauthlib                          3.2.2\n",
      "openai                            0.27.8\n",
      "opt-einsum                        3.3.0\n",
      "packaging                         21.2\n",
      "pandas                            1.3.4\n",
      "pandocfilters                     1.5.0\n",
      "parso                             0.8.3\n",
      "path                              16.7.1\n",
      "pathspec                          0.9.0\n",
      "patsy                             0.5.2\n",
      "pexpect                           4.8.0\n",
      "pickleshare                       0.7.5\n",
      "Pillow                            9.0.1\n",
      "pip                               21.2.4\n",
      "platformdirs                      2.6.2\n",
      "plotly                            5.6.0\n",
      "pluggy                            1.0.0\n",
      "portalocker                       2.7.0\n",
      "prometheus-client                 0.13.1\n",
      "prompt-toolkit                    3.0.20\n",
      "protobuf                          4.24.1\n",
      "psutil                            5.8.0\n",
      "psycopg2                          2.9.3\n",
      "ptyprocess                        0.7.0\n",
      "pure-eval                         0.2.2\n",
      "py                                1.10.0\n",
      "py4j                              0.10.9.5\n",
      "pyarrow                           6.0.0\n",
      "pyasn1                            0.5.0\n",
      "pyasn1-modules                    0.3.0\n",
      "pycparser                         2.21\n",
      "pyflakes                          2.5.0\n",
      "Pygments                          2.11.2\n",
      "PyGObject                         3.36.0\n",
      "PyJWT                             2.8.0\n",
      "pynndescent                       0.5.10\n",
      "pyodbc                            4.0.32\n",
      "pyparsing                         2.4.7\n",
      "pyright                           1.1.283\n",
      "pyrsistent                        0.18.0\n",
      "pytest                            6.2.5\n",
      "python-apt                        2.0.1+ubuntu0.20.4.1\n",
      "python-dateutil                   2.8.2\n",
      "python-lsp-jsonrpc                1.0.0\n",
      "python-lsp-server                 1.6.0\n",
      "pytz                              2021.3\n",
      "PyYAML                            6.0.1\n",
      "pyzmq                             22.3.0\n",
      "querystring-parser                1.2.4\n",
      "rapidfuzz                         3.2.0\n",
      "regex                             2023.8.8\n",
      "requests                          2.27.1\n",
      "requests-oauthlib                 1.3.1\n",
      "requests-unixsocket               0.2.0\n",
      "retry                             0.9.2\n",
      "rope                              0.22.0\n",
      "rsa                               4.9\n",
      "ruamel.yaml                       0.17.32\n",
      "ruamel.yaml.clib                  0.2.7\n",
      "s3transfer                        0.5.0\n",
      "safetensors                       0.3.2\n",
      "scikit-learn                      1.0.2\n",
      "scipy                             1.7.3\n",
      "seaborn                           0.11.2\n",
      "Send2Trash                        1.8.0\n",
      "sentence-transformers             2.2.2\n",
      "sentencepiece                     0.1.99\n",
      "setuptools                        61.2.0\n",
      "six                               1.16.0\n",
      "smart-open                        6.3.0\n",
      "smmap                             5.0.0\n",
      "soupsieve                         2.3.1\n",
      "SQLAlchemy                        2.0.20\n",
      "sqlparse                          0.4.4\n",
      "ssh-import-id                     5.10\n",
      "stack-data                        0.2.0\n",
      "statsmodels                       0.13.2\n",
      "sympy                             1.12\n",
      "tabulate                          0.9.0\n",
      "tenacity                          8.0.1\n",
      "tensorboard                       2.13.0\n",
      "tensorboard-data-server           0.7.1\n",
      "tensorflow                        2.13.0\n",
      "tensorflow-estimator              2.13.0\n",
      "tensorflow-io-gcs-filesystem      0.33.0\n",
      "termcolor                         2.3.0\n",
      "terminado                         0.13.1\n",
      "testpath                          0.5.0\n",
      "threadpoolctl                     2.2.0\n",
      "tokenize-rt                       4.2.1\n",
      "tokenizers                        0.13.3\n",
      "toml                              0.10.2\n",
      "tomli                             1.2.2\n",
      "torch                             2.0.1\n",
      "torchvision                       0.15.2\n",
      "tornado                           6.1\n",
      "tqdm                              4.66.1\n",
      "traitlets                         5.1.1\n",
      "transformers                      4.31.0\n",
      "triton                            2.0.0\n",
      "typing_extensions                 4.5.0\n",
      "ujson                             5.1.0\n",
      "umap-learn                        0.5.3\n",
      "unattended-upgrades               0.1\n",
      "urllib3                           1.26.9\n",
      "virtualenv                        20.8.0\n",
      "wcwidth                           0.2.5\n",
      "webencodings                      0.5.1\n",
      "websocket-client                  1.6.1\n",
      "Werkzeug                          2.3.7\n",
      "whatthepatch                      1.0.4\n",
      "wheel                             0.37.0\n",
      "widgetsnbextension                3.6.1\n",
      "wrapt                             1.15.0\n",
      "yapf                              0.31.0\n",
      "yarl                              1.9.2\n",
      "zipp                              3.16.2\n"
     ]
    }
   ],
   "source": [
    "%pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "38b64183-34df-46b6-b1c9-6bbe78776fd9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.databricks.v1+bamboolib_hint": "{\"pd.DataFrames\": [], \"version\": \"0.0.1\"}",
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/databricks/python/lib/python3.9/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd, numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, classification_report, confusion_matrix\n",
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8a1a5c73-5356-4b00-89a8-c87c775a321a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd, numpy as np\n",
    "DBFS = \"/dbfs/FileStore/tables/OFFSHORE/\"\n",
    "DBFO = \"/dbfs/FileStore/tables/OFFSHORE/\"\n",
    "DBFM = \"/dbfs/FileStore/tables/MALLIK/\"\n",
    "DBFR = \"/dbfs/FileStore/tables/OFFSHORE_RESULTS/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "323b9a6b-839b-432c-b6a5-f246845c4e3a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/databricks/python/lib/python3.9/site-packages/IPython/core/interactiveshell.py:3378: DtypeWarning: Columns (9) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "# Reading PIMMART data\n",
    "pim_gtin_mapped = pd.read_csv(DBFR + \"PIM_Data_New_50_82Mn.csv\", dtype=object)\n",
    "for i in ['SUBCOM_CD', 'DPT_CD', 'COM_CD','PMY_DPT_CD', 'REC_DPT_CD', 'ITM_ID', 'GTIN']:\n",
    "    pim_gtin_mapped[i] = pim_gtin_mapped[i].astype(np.float64)\n",
    "\n",
    "# Reading Syndigo 259K data\n",
    "synd_ALL = pd.read_csv(DBFR + 'Syndigo_Final_ALL.csv') # 259k Syndigo Data\n",
    "for i in ['SUBCOM_CD', 'DPT_CD', 'COM_CD', 'GTIN', 'ITM_ID', 'PMY_DPT_CD']:\n",
    "    synd_ALL[i] = synd_ALL[i].astype(np.float64)\n",
    "\n",
    "# Trimming empty spaces from all columns\n",
    "df_obj = synd_ALL.select_dtypes(['object'])\n",
    "synd_ALL[df_obj.columns] = df_obj.apply(lambda x: x.str.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0add1fd8-ce00-476d-8ef5-148dd7ed93c8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "syndigo_mapped = synd_ALL\n",
    "pimmart = pim_gtin_mapped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "468865de-5785-4aa8-88ce-eb09127442f3",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "syndigo_mapped.drop_duplicates('GTIN', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "35a8bc41-1917-40ec-942e-c78e178a71b3",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "syndigo_mapped['ITEM_SUBCOM_text'] = \\\n",
    "(syndigo_mapped.VND_ECOM_DSC + ' ' + syndigo_mapped.SUBCOM_DSC).fillna('').str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "573044f9-3feb-48ea-9744-48d5d9c89b92",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[9]: Food / Beverages                            131593\n",
      "Health & Beauty                              62259\n",
      "Beer / Wine / Spirits                        17992\n",
      "Cleaning & Janitorial                         9084\n",
      "Livestock & Pet Supplies                      6325\n",
      "Kitchen & Bathroom                            5268\n",
      "Home & Venue Decoration                       3924\n",
      "Toys / Games / Hobbies                        3191\n",
      "Gardening & Outdoors                          2208\n",
      "Childcare                                     2111\n",
      "Office Supplies                               1671\n",
      "Electronics                                   1499\n",
      "Apparel                                       1283\n",
      "Lighting & Fans                               1252\n",
      "Tobacco Products                              1252\n",
      "Not classified                                1018\n",
      "Hardware                                       923\n",
      "Arts & Crafts                                  803\n",
      "Automotive                                     778\n",
      "Appliances                                     689\n",
      "Sports & Outdoor Recreation Equipment          684\n",
      "Hospitality Supplies                           496\n",
      "Tools                                          474\n",
      "Books & Videos                                 377\n",
      "Electrical                                     215\n",
      "Heating / Ventilation / Air Conditioning       196\n",
      "Plumbing & Water Service                       172\n",
      "Paints & Coatings                               60\n",
      "Building Supplies                               40\n",
      "Power Sports                                    39\n",
      "Furniture                                       37\n",
      "Marine                                          16\n",
      "Flooring                                        13\n",
      "Material Handling                                6\n",
      "Agricultural Equipment                           3\n",
      "Power Transmission & Motion Control              1\n",
      "Musical Instruments                              1\n",
      "Name: Level 1, dtype: int64"
     ]
    }
   ],
   "source": [
    "syndigo_mapped['Level 1'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "eeb8719e-7b17-40ae-a855-dc4f3df7a006",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vect = TfidfVectorizer(ngram_range= (1,2), max_features = 800000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d61f83c5-88d4-4788-beae-41be8e02577c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[11]: Food / Beverages                            131593\n",
      "Health & Beauty                              62259\n",
      "Beer / Wine / Spirits                        17992\n",
      "Cleaning & Janitorial                         9084\n",
      "Livestock & Pet Supplies                      6325\n",
      "Kitchen & Bathroom                            5268\n",
      "Home & Venue Decoration                       3924\n",
      "Toys / Games / Hobbies                        3191\n",
      "Gardening & Outdoors                          2208\n",
      "Childcare                                     2111\n",
      "Office Supplies                               1671\n",
      "Electronics                                   1499\n",
      "Apparel                                       1283\n",
      "Lighting & Fans                               1252\n",
      "Tobacco Products                              1252\n",
      "Not classified                                1018\n",
      "Hardware                                       923\n",
      "Arts & Crafts                                  803\n",
      "Automotive                                     778\n",
      "Appliances                                     689\n",
      "Sports & Outdoor Recreation Equipment          684\n",
      "Hospitality Supplies                           496\n",
      "Tools                                          474\n",
      "Books & Videos                                 377\n",
      "Electrical                                     215\n",
      "Heating / Ventilation / Air Conditioning       196\n",
      "Plumbing & Water Service                       172\n",
      "Paints & Coatings                               60\n",
      "Building Supplies                               40\n",
      "Power Sports                                    39\n",
      "Furniture                                       37\n",
      "Marine                                          16\n",
      "Flooring                                        13\n",
      "Material Handling                                6\n",
      "Agricultural Equipment                           3\n",
      "Power Transmission & Motion Control              1\n",
      "Musical Instruments                              1\n",
      "Name: Level 1, dtype: int64"
     ]
    }
   ],
   "source": [
    "syndigo_mapped['Level 1'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1e3e259c-2f33-49ef-a16a-756a94d7db52",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[22]: [('chips,', 0.7620069980621338),\n",
      " ('puffed/popped', 0.692810595035553),\n",
      " ('veggie/grain', 0.6568589806556702),\n",
      " ('chips.', 0.6461755037307739),\n",
      " ('popped', 0.6434525847434998),\n",
      " ('snacks', 0.6221342086791992),\n",
      " ('crisps', 0.6071634888648987),\n",
      " ('thins', 0.5962806344032288),\n",
      " ('<', 0.5704862475395203),\n",
      " ('kurokirishima', 0.5686668157577515)]"
     ]
    }
   ],
   "source": [
    "### import word2vec model trained on entire PIMMART data\n",
    "from gensim.models import Word2Vec, KeyedVectors\n",
    "model = KeyedVectors.load_word2vec_format('/dbfs/FileStore/tables/DATA_SCIENCE/w2vmodel_053123_PIM_ALL.bin', binary=True)\n",
    "model.most_similar('chips')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "98766c3d-85af-4dd1-a2ac-4ccd6a796a34",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Build item vectors\n",
    "def get_item_vector(item_vocab):\n",
    "    vect = np.zeros_like(model.get_vector('chips'))\n",
    "    for word in item_vocab:\n",
    "        if word in model:\n",
    "            vect += model.get_vector(word)\n",
    "    return vect#/max(1,len(item_vocab))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "478d3b32-9d94-4764-957f-d0fb53421831",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## RUN UNTIL HERE only ONCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7ce3bdb0-1a92-436e-91b4-3d70c35d42c4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "level__1 = \"Beer / Wine / Spirits\"\n",
    "filenamee = \"BEER_WINE_SPIRITS\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5231bbdc-be06-4e19-acf9-c2713de758cc",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[24]: Meal Kits (Perishable)                                        309\n",
      "Baby & Toddler Food                                          1623\n",
      "Produce                                                      1649\n",
      "Meat / Poultry / Seafood / Meat Substitutes (Perishable)     3976\n",
      "Bakery / Deli                                                5333\n",
      "Dairy & Egg Products                                         9018\n",
      "Frozen Foods                                                13582\n",
      "Beverages                                                   21240\n",
      "Grocery                                                     74863\n",
      "Name: Level 2, dtype: int64"
     ]
    }
   ],
   "source": [
    "# level__1 = \"Beer / Wine / Spirits\"\n",
    "# filenamee = \"BEER_WINE_SPIRITS\"\n",
    "\n",
    "level__1 = \"Cleaning & Janitorial\"\n",
    "filenamee = \"CLEANING_JANITORIAL\"\n",
    "\n",
    "level__1 = \"Toys / Games / Hobbies\"\n",
    "filenamee = \"TOYS_GAMES_HOBBIES\"\n",
    "\n",
    "level__1 = \"Office Supplies\"\n",
    "\n",
    "level__1 = \"Building Supplies\"\n",
    "filenamee = \"Building_Supplies\"\n",
    "\n",
    "level__1 = \"Flooring\"\n",
    "filenamee = \"FLOORING\"\n",
    "\n",
    "level__1 = \"Beer / Wine / Spirits\"\n",
    "filenamee = \"BEER_WINE_SPIRITS\"\n",
    "\n",
    "\n",
    "# Electronics\n",
    "\n",
    "level__1 = \"Food / Beverages\"\n",
    "filenamee = \"Food / Beverages\"\n",
    "syndigo_mapped[syndigo_mapped['Level 1']==level__1]['Level 2'].value_counts(ascending=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "04ef7292-f60c-4cc7-8522-4ce36889eadb",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### TFIDF vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "beed20df-c5be-47e1-bf03-fcf71fd0be85",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed : []\n"
     ]
    }
   ],
   "source": [
    "level_1 = level__1\n",
    "subset_df = syndigo_mapped[syndigo_mapped['Level 1'] == level_1]\n",
    "series = syndigo_mapped[syndigo_mapped['Level 1']==level_1]['Level 2'].value_counts(ascending=True)\n",
    "print(\"Removed :\", subset_df[subset_df['Level 2'].isin(series[series==1].index.tolist())].index.tolist())\n",
    "if series.tolist():\n",
    "    subset_df = subset_df.drop(subset_df[subset_df['Level 2'].isin(series[series==1].index.tolist())].index)\n",
    "vect_subset = TfidfVectorizer(ngram_range = (1,2), max_features = 50000)\n",
    "X_subset = vect_subset.fit_transform(subset_df.ITEM_SUBCOM_text)\n",
    "level2_id_map = dict(zip(subset_df['Level 2'].fillna('Other').unique(), range(subset_df['Level 2'].fillna('Other').nunique())))\n",
    "id2_level_map = dict(zip(range(subset_df['Level 2'].fillna('Other').nunique()), subset_df['Level 2'].fillna('Other').unique()))\n",
    "y_subset  = subset_df['Level 2'].fillna('Other').map(level2_id_map)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "377faaa9-6bef-42b2-b354-c4e17c60278a",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### word2vec Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b6e5f1b3-0c4d-46b9-8f81-4a57a29c50fe",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "x_subset_w2v = np.array(list(subset_df.ITEM_SUBCOM_text.apply(lambda x: get_item_vector(x.split(' ')))))\n",
    "level2_id_map = dict(zip(subset_df['Level 2'].fillna('Other').unique(), range(subset_df['Level 2'].fillna('Other').nunique())))\n",
    "id2_level_map = dict(zip(range(subset_df['Level 2'].fillna('Other').nunique()), subset_df['Level 2'].fillna('Other').unique()))\n",
    "#y_subset_w2v  = subset_df['Level 2'].fillna('Other').map(level2_id_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ee8a56c3-3d12-4e90-bd64-02a7d47e979f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "A_train, A_test, B_train, B_test = train_test_split(subset_df.GTIN.tolist(), subset_df['Level 2'].tolist(), test_size=0.2, stratify=y_subset, random_state=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_subset, y_subset.values, test_size= 0.2, stratify=y_subset, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3d6e7c46-7629-4b71-9a10-10026d4fbb3d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "X_train_w2v, X_test_w2v, y_train_w2v, y_test_w2v = train_test_split(x_subset_w2v, y_subset.values, test_size= 0.2, stratify=y_subset, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1e2c16b8-861d-42f9-9db1-520eefbf2b26",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test size: 26319\n",
      "Train size: 105274\n",
      "\n",
      "Training - \"Food / Beverages\"\n",
      "Out[29]: LogisticRegression(C=100, multi_class='multinomial', solver='saga')"
     ]
    }
   ],
   "source": [
    "lr_tf = LogisticRegression(C = 100, multi_class = 'multinomial', solver = 'saga')\n",
    "print(f\"Test size: {len(A_test)}\\nTrain size: {len(A_train)}\\n\")\n",
    "print(f\"Training - \\\"{level_1}\\\"\")\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "lr_tf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b655f2fd-4522-485c-964c-aa1bceb61116",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test size: 26319\n",
      "Train size: 105274\n",
      "\n",
      "Training - w2v \"Food / Beverages\"\n",
      "Out[21]: LogisticRegression(C=100, multi_class='multinomial', solver='saga')"
     ]
    }
   ],
   "source": [
    "lr_w2v = LogisticRegression(C = 100, multi_class = 'multinomial', solver = 'saga')\n",
    "print(f\"Test size: {len(A_test)}\\nTrain size: {len(A_train)}\\n\")\n",
    "print(f\"Training - w2v \\\"{level_1}\\\"\")\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "lr_w2v.fit(X_train_w2v, y_train_w2v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "782a0c6f-3623-4266-a529-c01c26b982b0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[61]: {'C': 100,\n",
      " 'class_weight': None,\n",
      " 'dual': False,\n",
      " 'fit_intercept': True,\n",
      " 'intercept_scaling': 1,\n",
      " 'l1_ratio': None,\n",
      " 'max_iter': 100,\n",
      " 'multi_class': 'multinomial',\n",
      " 'n_jobs': None,\n",
      " 'penalty': 'l2',\n",
      " 'random_state': None,\n",
      " 'solver': 'saga',\n",
      " 'tol': 0.0001,\n",
      " 'verbose': 0,\n",
      " 'warm_start': False}"
     ]
    }
   ],
   "source": [
    "lr_w2v.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e1a4e492-c23a-4cbf-a6b3-0e600aeef9fb",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "lr_tf = LogisticRegressionCV(Cs = [1,10,100,1000], multi_class = 'multinomial', solver = 'saga')\n",
    "print(f\"Test size: {len(A_test)}\\nTrain size: {len(A_train)}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "91ac33a6-ad52-4e18-b248-ee262ec5b9ba",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Display TFIDF metrics\n",
      "                                                          precision    recall  f1-score   support\n",
      "\n",
      "                                    Dairy & Egg Products       0.94      0.93      0.94      1804\n",
      "                                                 Grocery       0.95      0.96      0.96     14973\n",
      "                                               Beverages       0.97      0.96      0.97      4248\n",
      "Meat / Poultry / Seafood / Meat Substitutes (Perishable)       0.74      0.72      0.73       795\n",
      "                                            Frozen Foods       0.91      0.91      0.91      2716\n",
      "                                           Bakery / Deli       0.62      0.55      0.58      1067\n",
      "                                     Baby & Toddler Food       0.89      0.90      0.90       324\n",
      "                                                 Produce       0.73      0.65      0.69       330\n",
      "                                  Meal Kits (Perishable)       0.52      0.21      0.30        62\n",
      "\n",
      "                                                accuracy                           0.93     26319\n",
      "                                               macro avg       0.81      0.76      0.77     26319\n",
      "                                            weighted avg       0.92      0.93      0.92     26319\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Display TFIDF metrics\")\n",
    "preds_test = lr_tf.predict(X_test)\n",
    "preds_train = lr_tf.predict(X_train)\n",
    "print(classification_report(y_test, preds_test,labels = lr_tf.classes_, target_names = [id2_level_map[i] for i in lr_tf.classes_]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2cd49eb8-931d-4881-b31f-763bbad22ca1",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Display w2v version metrics\n",
      "                                                          precision    recall  f1-score   support\n",
      "\n",
      "                                    Dairy & Egg Products       0.89      0.88      0.88      1804\n",
      "                                                 Grocery       0.91      0.96      0.93     14973\n",
      "                                               Beverages       0.95      0.94      0.95      4248\n",
      "Meat / Poultry / Seafood / Meat Substitutes (Perishable)       0.69      0.68      0.68       795\n",
      "                                            Frozen Foods       0.86      0.82      0.84      2716\n",
      "                                           Bakery / Deli       0.58      0.30      0.39      1067\n",
      "                                     Baby & Toddler Food       0.86      0.89      0.88       324\n",
      "                                                 Produce       0.67      0.48      0.56       330\n",
      "                                  Meal Kits (Perishable)       0.36      0.08      0.13        62\n",
      "\n",
      "                                                accuracy                           0.89     26319\n",
      "                                               macro avg       0.75      0.67      0.69     26319\n",
      "                                            weighted avg       0.88      0.89      0.89     26319\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(' Display w2v version metrics')\n",
    "preds_test_w2v = lr_w2v.predict(X_test_w2v)\n",
    "preds_train_w2v = lr_w2v.predict(X_train_w2v)\n",
    "print(classification_report(y_test_w2v, preds_test_w2v,labels = lr_w2v.classes_, target_names = [id2_level_map[i] for i in lr_w2v.classes_]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3bceb8e8-d0bf-497a-be4b-2ff5adb2c80f",
     "showTitle": true,
     "title": "Ignore any warnings from this cell"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test size: 3599\n",
      "Train size: 14393\n",
      "\n",
      "Training - \"Beer / Wine / Spirits\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "",
       "errorSummary": "Cancelled",
       "errorTraceType": "html",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "preds = lr_tf.predict(X_test)\n",
    "preds_lrtf = preds\n",
    "probs = lr_tf.predict_proba(X_test)\n",
    "preds_train = lr_tf.predict(X_train)\n",
    "probs_train = lr_tf.predict_proba(X_train)\n",
    "print(f\"Done Training - \\\"{level_1}\\\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6dda9f8b-f131-4178-9a9e-0fe8bd02ddc4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    }
   ],
   "source": [
    "level_num = []\n",
    "testProobs = []\n",
    "number = 1\n",
    "\n",
    "print(len(preds))\n",
    "for i in range(len(preds)):\n",
    "    for j in range(number):\n",
    "        try:\n",
    "            level_num.append(int(np.where(probs[i]==probs[i][np.argsort(probs[i])][::-1][:3][j])[0]))\n",
    "        except TypeError:\n",
    "            level_num.append(int(np.where(probs[i]==probs[i][np.argsort(probs[i])][::-1][:3][2])[0][0]))\n",
    "            print(\"problem occurred with: \", i, j, flush=True)\n",
    "    testProobs.append(probs[i][np.argsort(probs[i])][::-1][:1])\n",
    "\n",
    "test_new_proobs = []\n",
    "for i in range(len(testProobs)):\n",
    "    test_new_proobs.append(testProobs[i].tolist())\n",
    "test_new_proobs = [element for sublist in list(test_new_proobs) for element in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5d1f23cd-b044-493a-999c-25de1351083e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27\n"
     ]
    }
   ],
   "source": [
    "level_num = []\n",
    "trainProobs = []\n",
    "\n",
    "print(len(preds_train))\n",
    "for i in range(len(preds_train)):\n",
    "    for j in range(number):\n",
    "        try:\n",
    "            level_num.append(int(np.where(probs_train[i]==probs_train[i][np.argsort(probs_train[i])][::-1][:3][j])[0]))\n",
    "        except TypeError:\n",
    "            level_num.append(int(np.where(probs_train[i]==probs_train[i][np.argsort(probs_train[i])][::-1][:3][2])[0][0]))\n",
    "            print(\"problem occurred with: \", i, j, flush=True)\n",
    "    trainProobs.append(probs_train[i][np.argsort(probs_train[i])][::-1][:1]) \n",
    "\n",
    "train_new_proobs = []\n",
    "for i in range(len(trainProobs)):\n",
    "    train_new_proobs.append(trainProobs[i].tolist())\n",
    "train_new_proobs = [element for sublist in list(train_new_proobs) for element in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "df06039a-7117-48ed-9673-2c712f1b0d2e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "testLevels = []\n",
    "for j in y_test:\n",
    "    testLevels.append([i for i in level2_id_map if level2_id_map[i]==j][0])\n",
    "\n",
    "testLevelss = []\n",
    "for j in preds:\n",
    "    testLevelss.append([i for i in level2_id_map if level2_id_map[i]==j][0])\n",
    "\n",
    "trainLevelss = []\n",
    "for j in preds_train:\n",
    "    trainLevelss.append([i for i in level2_id_map if level2_id_map[i]==j][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5dba2fa9-97bc-4807-a06b-6f7a8f2189b3",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------\n",
      "FINAL COUNTS:\n",
      "---------------------------------------------\n",
      "1) 34\n",
      "2) 34\n",
      "3) 34\n",
      "4) 34\n",
      "5) 34\n",
      "6) 34\n"
     ]
    }
   ],
   "source": [
    "print(\"---------------------------------------------\\nFINAL COUNTS:\\n---------------------------------------------\")\n",
    "print(\"1)\", len(A_test + A_train))\n",
    "print(\"2)\", len(['Test']*len(A_test) + ['Train']*len(A_train)))\n",
    "print(\"3)\", len(B_test + B_train))\n",
    "print(\"4)\", len(testLevels + B_train))\n",
    "print(\"5)\", len(testLevelss + trainLevelss))\n",
    "print(\"6)\", int(len(test_new_proobs + train_new_proobs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c7349f53-6f3a-4a5c-83d4-70ee595fb4b6",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "data = {\n",
    "    'GTIN' : A_test + A_train,\n",
    "    'Source': ['Test']*len(A_test) + ['Train']*len(A_train),\n",
    "    'Actual Level 2' : B_test + B_train,\n",
    "    'Actuals' : testLevels + B_train,\n",
    "    'Predictions' : testLevelss + trainLevelss,\n",
    "    'Scores' : test_new_proobs + train_new_proobs,\n",
    "    'L1 Name' : level_1\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df = df.merge(pim_gtin_mapped[['GTIN', 'ITM_ID', 'PMY_DPT_CD', 'PMY_DPT_DSC', 'REC_DPT_CD',\n",
    "    'REC_DPT_DSC', 'DPT_CD', 'DPT_DSC', 'COM_CD', 'COM_DSC', 'SUBCOM_CD',\n",
    "    'SUBCOM_DSC', 'VND_ECOM_DSC']], on='GTIN', how='left')\n",
    "df = df[['ITM_ID', 'GTIN', 'PMY_DPT_CD', 'PMY_DPT_DSC', 'REC_DPT_CD', 'REC_DPT_DSC', 'DPT_CD',\n",
    "    'DPT_DSC', 'COM_CD', 'COM_DSC', 'SUBCOM_CD', 'SUBCOM_DSC',\n",
    "    'VND_ECOM_DSC', 'Source', 'Actual Level 2', 'Actuals', 'Predictions', 'Scores', 'L1 Name']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "27ee1c73-72c8-4226-a81b-10f4556206e8",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Keep the output of the below cell for all Level 1 executed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "74055d3e-c020-4172-9b52-44358f40546a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building_Supplies.csv\n"
     ]
    }
   ],
   "source": [
    "df.to_csv(DBFO + filenamee + '.csv', index=False)\n",
    "print(f\"{filenamee}.csv\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Syndigo Mapping MachineLearning_TFIDF_W2vec_Comparison",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
