{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# smote_L1_L2_Syndigo Mapping ML\n",
    "  - module name: smote_L1_L2_Syndigo ML.ipynb\n",
    "  - Purpose: Combine Level 1 & Level 2 from  Syndigo to build model\n",
    "             - Apply TFIDF and W2vec imbedding methods \n",
    "  - Excluding non-item SUBCOMs from un-label data and including  ‘stratify= y’ when I did train_test_split.       \n",
    "  - Basse on adj_typ to iInclude SMOTE for imbalance data \n",
    "    -adj_typ\n",
    "      - no_smote: no adjustment\n",
    "      - smote : Apply SMOTE(k_neighbors =1) for oversample\n",
    "      - smote_undsmp:   Apply SMOTE(k_neighbors =1) for oversample and RandomUnderSampler() for undersample \n",
    "     - The function 'prepare_data_2' will base on adj_typ to create X, y for modeling   \n",
    "      \n",
    "   - Notes:\n",
    "     - In order to apply ‘stratify= y’ in train_test_split,   \n",
    "       - The code needs to drop count of y  = 1. PLease  refer to the function 'prepare_data_2'  \n",
    "       - it needs to define k_neighbors = 1 for SMOTE\n",
    "     - Will focus on W2vec only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data_1():\n",
    "    pgm = inspect.currentframe().f_code.co_name  \n",
    "    start_time = time.time() \n",
    "    # Reading PIMMART data\n",
    "    pim_gtin_mapped = pd.read_csv(DBFR + \"PIM_Data_New_50_82Mn.csv\", dtype=object) # (5082212, 24)\n",
    "\n",
    "    SUBCOMS_excluded = ['INVENTORY VALUES','MISC SALES TRANS','MISC SALES TRANS (NON TAX)','CENTRAL SUPPLIES', \\\n",
    "                        'MISC SALES TRANS (TX TAXABLE)','COUPON','MISCELLANEOUS INCOME','CRV/EXCISE TAX NT/NF', \\\n",
    "                        'CRV DEPOSIT NT/F','CRV DEPOSIT T/NF','MISCELLANEOUS REFUNDS','CUSTOMER EXPENSES','ROUND UP COUPONS']\n",
    "    pim_gtin_mapped = pim_gtin_mapped[~pim_gtin_mapped.SUBCOM_DSC.isin(SUBCOMS_excluded)]\n",
    "    print(f'Before drop pim_gtin_mapped.shape {pim_gtin_mapped.shape}')\n",
    "    print(f'After drop pim_gtin_mapped.shape {pim_gtin_mapped.shape}')\n",
    "    for i in ['SUBCOM_CD', 'DPT_CD', 'COM_CD','PMY_DPT_CD', 'REC_DPT_CD', 'ITM_ID', 'GTIN']:\n",
    "        pim_gtin_mapped[i] = pim_gtin_mapped[i].astype(np.float64)\n",
    "    \n",
    "    # Reading Syndigo 259K data\n",
    "    synd_ALL = pd.read_csv(DBFR + 'Syndigo_Final_ALL.csv', dtype='unicode') # 259k Syndigo Data\n",
    "    for i in ['SUBCOM_CD', 'DPT_CD', 'COM_CD', 'GTIN', 'ITM_ID', 'PMY_DPT_CD']:\n",
    "        synd_ALL[i] = synd_ALL[i].astype(np.float64)\n",
    "    \n",
    "    # Stripping spaces from all columns\n",
    "    df_obj = synd_ALL.select_dtypes(['object'])\n",
    "    synd_ALL[df_obj.columns] = df_obj.apply(lambda x: x.str.strip())\n",
    "    \n",
    "    syndigo_mapped = synd_ALL\n",
    "    pimmart = pim_gtin_mapped\n",
    "    syndigo_mapped.drop_duplicates('GTIN', inplace = True)\n",
    "\n",
    "    \n",
    "    syndigo_mapped['ITEM_SUBCOM_text'] = \\\n",
    "    (syndigo_mapped.VND_ECOM_DSC + ' ' + syndigo_mapped.SUBCOM_DSC).fillna('').str.lower()\n",
    "    #syndigo_mapped['Level 1'].value_counts()\n",
    "    #print(f'syndigo_mapped.shape {syndigo_mapped.shape}') \n",
    "    #print(f'syndigo_mapped.info() {syndigo_mapped.info()}') \n",
    "    #print(f'syndigo_mapped.head() {syndigo_mapped.head()}') \n",
    "    #print(f'syndigo_mapped.columns {syndigo_mapped.columns}') \n",
    "    \n",
    "    syndigo_mapped['l1_l2'] = syndigo_mapped['Level 1'] + ' + ' + syndigo_mapped['Level 2']\n",
    "    #print(f\"syndigo_mapped['l1_l2'].value_counts() {syndigo_mapped['l1_l2'].value_counts(dropna = False)}\")    \n",
    "    return syndigo_mapped, pim_gtin_mapped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unterminated string literal (detected at line 21) (4084535122.py, line 21)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[44], line 21\u001b[1;36m\u001b[0m\n\u001b[1;33m    print(f'embed_typ == 'tfidf')\u001b[0m\n\u001b[1;37m                               ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m unterminated string literal (detected at line 21)\n"
     ]
    }
   ],
   "source": [
    "def prepare_data_2(samp_frac = 1, embed_typ):\n",
    "  \n",
    "    start_time = time.time()\n",
    "    pgm = inspect.currentframe().f_code.co_name \n",
    "    global syndigo_mapped, model\n",
    "    print(f' samp_frac = {samp_frac}') \n",
    "    syndigo_mapped = syndigo_mapped_bkup.copy()    \n",
    "    print (f'Before sample syndigo_mapped.shape {syndigo_mapped.shape }')\n",
    "           \n",
    "    whole_frac = 1\n",
    "    if samp_frac  < whole_frac :   syndigo_mapped = syndigo_mapped.sample(frac = samp_frac,  random_state=42)   \n",
    "    print (f'After sample syndigo_mapped.shape {syndigo_mapped.shape }')    \n",
    "    \n",
    "    \n",
    "    series = syndigo_mapped['l1_l2'].value_counts(ascending=True)\n",
    "    if series.tolist():\n",
    "       syndigo_mapped = syndigo_mapped.drop(syndigo_mapped[syndigo_mapped['l1_l2'].isin(series[series < 3 ].index.tolist())].index)\n",
    "       print (f'after drop syndigo_mapped.shape {syndigo_mapped.shape }')                     \n",
    "    \n",
    "    if embed_typ == 'tfidf': \n",
    "        print(f'embed_typ == 'tfidf')\n",
    "        vect = TfidfVectorizer(ngram_range = (1,2), max_features = 50000) \n",
    "        X = vect.fit_transform(syndigo_mapped.ITEM_SUBCOM_text) #scipy.sparse._csr.csr_matrix\n",
    "    else:\n",
    "        print(f'embed_typ == 'W2vec')              \n",
    "        model = KeyedVectors.load_word2vec_format(DBFO + 'w2vmodel_053123_PIM_ALL.bin', binary=True)\n",
    "        X = np.array(list(syndigo_mapped.ITEM_SUBCOM_text.apply(lambda x: get_item_vector(x.split(' ')))))\n",
    "\n",
    "    l1_l2_id_map = dict(zip(syndigo_mapped['l1_l2'].fillna('Other').unique(), range(syndigo_mapped['l1_l2'].fillna('Other').nunique())))\n",
    "    id_l1_l2_map = dict(zip(range(syndigo_mapped['l1_l2'].fillna('Other').nunique()), syndigo_mapped['l1_l2'].fillna('Other').unique()))\n",
    "    y  = syndigo_mapped['l1_l2'].fillna('Other').map(l1_l2_id_map) \n",
    "           \n",
    "    counter = Counter(y)\n",
    "    for k,v in counter.items():\n",
    "        per = v / len(y) * 100\n",
    "        print('Class=%d, n=%d (%.3f%%)' % (k, v, per))\n",
    "    # plot the distribution\n",
    "    pyplot.bar(counter.keys(), counter.values())\n",
    "    pyplot.show()           \n",
    "    #y_list= list(y)\n",
    "    #y = pd.Series(list(filter (lambda z: y_list.count(z) > 1, y_list)))\n",
    "    #\n",
    "    end_time = time.time()   \n",
    "    desc = f' Elapse_time for \"{pgm}\".' \n",
    "    elapse_time (  start_time, end_time, desc)\n",
    "    return  X, y, l1_l2_id_map, id_l1_l2_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build item vectors\n",
    "def get_item_vector(item_vocab):\n",
    "    vect = np.zeros_like(model.get_vector('chips'))\n",
    "    for word in item_vocab:\n",
    "        if word in model:\n",
    "            vect += model.get_vector(word)\n",
    "    return vect#/max(1,len(item_vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def proc_predict(test_size,c_parm, embed_typ, adj_typ):\n",
    "     start_time = time.time()\n",
    "     pgm = inspect.currentframe().f_code.co_name   \n",
    "     global A_train, A_test, B_train, B_test, X_train, X_test, y_train, y_test\n",
    "     A_train, A_test, B_train, B_test = train_test_split(syndigo_mapped.GTIN.tolist(), syndigo_mapped['l1_l2'].tolist(), test_size=test_size,  random_state=42, stratify= y)\n",
    "     \n",
    "     X_train, X_test, y_train, y_test = train_test_split(X, y, test_size= test_size,  random_state=42, stratify= y)\n",
    "\n",
    "     if adj_typ == 'no_smote': pass\n",
    "     elif  adj_typ == 'smote':\n",
    "        oversample = SMOTE(k_neighbors =1)  \n",
    "        X_train, y_train  = oversample.fit_resample(X_train, y_train) \n",
    "        A_train =  np.array(A_train).reshape(-1, 1)\n",
    "        A_train, B_train  = oversample.fit_resample(A_train, B_train) \n",
    "     elif  adj_typ == 'smote_undsmp':\n",
    "        over = SMOTE(k_neighbors = 1)\n",
    "        under = RandomUnderSampler()\n",
    "        steps = [('o', over), ('u', under)]\n",
    "        pipeline = Pipeline(steps=steps)\n",
    "        X_train, y_train  = pipeline.fit_resample(X_train, y_train )\n",
    "        A_train =  np.array(A_train.reshape(-1, 1))\n",
    "        A_train, B_train  = pipeline.fit_resample(A_train, B_train )\n",
    "     else: pass        \n",
    "    \n",
    "     print(f'Build model for  embed_typ {embed_typ} and  adj_typ {adj_typ}; len  of y_train = {len(y_train)}, len  of B_train = {len(B_train)}'  ) \n",
    "     lr_tf = LogisticRegression(C = c_parm, multi_class = 'multinomial', solver = 'saga', n_jobs=-1)\n",
    "     \n",
    "     print(f\"Training starts for test_size = {test_size}, c_parm = {c_parm} \")\n",
    "     lr_tf.fit(X_train, y_train)\n",
    "     preds = lr_tf.predict(X_test)\n",
    "     #print(f\"type(preds) {type(preds)} len(preds) {len(preds)} \\n preds[0:10] {preds[0:10]}\")\n",
    "     preds_lrtf = preds\n",
    "     probs = lr_tf.predict_proba(X_test)\n",
    "     #print(f\"type(probs) {type(probs)} len(probs) {len(probs)} \\n probs[0:10] {probs[0:10]}\")   \n",
    "     preds_train = lr_tf.predict(X_train)\n",
    "     #print(f\"type(preds_train) {type(preds_train)} len(preds_train) {len(preds_train)} \\n preds_train[0:10] {preds_train[0:10]} \")   \n",
    "     probs_train = lr_tf.predict_proba(X_train)\n",
    "     #print(f\"type(probs_train) {type(probs_train)} len(probs_train) {len(probs_train)} \\n probs_train[0:10] {probs_train[0:10]}\")   \n",
    "     #print(classification_report(y_test, preds_test,labels = lr_tf.classes_, target_names = [id2_level_map[i] for i in lr_tf.classes_]))\n",
    "     \n",
    "    \n",
    "    \n",
    "     #print(\"Accuracy = \",accuracy_score(y_test,preds))\n",
    "     #print(\"Display TFIDF metrics\")\n",
    "     #print(classification_report(y_test, preds,labels = lr_tf.classes_, target_names = [id_l1_l2_map[i] for i in lr_tf.classes_]))\n",
    "     filename = path + f'L1_l2_LR_{embed_typ}_{adj_typ}.pkl'\n",
    "   \n",
    "     pickle.dump(lr_tf, open(filename, 'wb'))\n",
    "\n",
    "     print(f\"Done Training \")\n",
    "     end_time = time.time()   \n",
    "     desc = f' Elapse_time for \"{pgm}\".' \n",
    "     elapse_time (  start_time, end_time, desc)\n",
    "     return preds, preds_lrtf, probs, preds_train, probs_train, lr_tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(test_size, c_parm, embed_typ, adj_typ):\n",
    "     start_time = time.time() \n",
    "     pgm = inspect.currentframe().f_code.co_name\n",
    "     global f1_score_weighted, f1_score_macro,f1_score_micro \n",
    "     l_metrics = []\n",
    "     print(f'Validation for c_parm = {c_parm}, test_size = {test_size}, and embed_type {embed_typ} ' ) \n",
    "     accuracy = accuracy_score(y_test,preds)\n",
    "     print(f\"Accuracy Score = {accuracy}\")\n",
    "     \n",
    "     f1_score_weighted = f1_score(y_test, preds, average=\"weighted\")\n",
    "     f1_score_macro    = f1_score(y_test, preds, average='macro')\n",
    "     f1_score_micro    = f1_score(y_test, preds, average='micro')  \n",
    "     print (f\" f1_score_weighted = {f1_score_weighted}\")\n",
    "     print (f\" f1_score_macro    = {f1_score_macro   }\")\n",
    "     print (f\" f1_score_micro    = {f1_score_micro   }\")\n",
    "     # Compute the Multiclass ROC AUC score\n",
    "     #multi_class = 'multinomial'\n",
    "     #score = roc_auc_score(y_test, preds, multi_class= multi_class)\n",
    "     #print(f\"ROC AUC score for Multiclass= {multi_class}: {score:.2f}\")\n",
    "\n",
    "     print(\"Display metrics\")\n",
    "     test_metrics = pd.DataFrame(classification_report(y_test, preds,labels = lr_tf.classes_, target_names = [id_l1_l2_map[i] for i in lr_tf.classes_],  output_dict= True)).T\n",
    "     #test_metrics = pd.DataFrame(classification_report(results_test.Actuals, results_test.Predictions, output_dict= True)).T \n",
    "     #print(test_metrics)\n",
    "     #Stest_metrics.to_csv('L1_L2_Test_Metrics_yue.csv')\n",
    "     #accuracy = 1\n",
    "     tab_name = f'{embed_typ}_L1_L2_cls_rpr_{adj_typ}'   \n",
    "     print(f'tab_name = {tab_name}')  \n",
    "     l_metrics = [embed_typ, adj_typ, test_size, c_parm, accuracy, f1_score_weighted, f1_score_macro,f1_score_micro ]\n",
    "     end_time = time.time()   \n",
    "     desc = f' Elapse_time for \"{pgm}\".' \n",
    "     elapse_time (  start_time, end_time, desc)    \n",
    "     return test_metrics, tab_name, l_metrics \n",
    "                               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def proc_append():\n",
    "    start_time = time.time()\n",
    "    pgm = inspect.currentframe().f_code.co_name     \n",
    "    test_new_proobs = []\n",
    "    \n",
    "    #print(f'len(preds)  {len(preds)}')\n",
    "    for i in range(len(preds)):\n",
    "        test_new_proobs.append(probs[i][np.argsort(probs[i])][::-1][:1].tolist())\n",
    "    test_new_proobs = [element for sublist in list(test_new_proobs) for element in sublist]\n",
    "    #print(f'test_new_proobs {test_new_proobs}')\n",
    "    \n",
    "    train_new_proobs = []\n",
    "    \n",
    "    #print(f'len(preds_train)  {len(preds_train)}')\n",
    "    for i in range(len(preds_train)):\n",
    "         test_new_proobs.append(probs_train[i][np.argsort(probs_train[i])][::-1][:1].tolist())\n",
    "    train_new_proobs = [element for sublist in list(train_new_proobs) for element in sublist]\n",
    "    #print(f'train_new_proobs {train_new_proobs}')  \n",
    "    \n",
    "    # process testLevels & trainLevelss \n",
    "    testLevels = []\n",
    "    for j in y_test:\n",
    "        testLevels.append([i for i in l1_l2_id_map if l1_l2_id_map[i]==j][0])\n",
    "    #print(f'testLevels {testLevels [0:10]}')\n",
    "    testLevelss = []\n",
    "    for j in preds:\n",
    "        testLevelss.append([i for i in l1_l2_id_map if l1_l2_id_map[i]==j][0])\n",
    "    #print(f'testLevelss {testLevelss [0:10]}')\n",
    "    \n",
    "    trainLevelss = []\n",
    "    for j in preds_train:\n",
    "        trainLevelss.append([i for i in l1_l2_id_map if l1_l2_id_map[i]==j][0])\n",
    "     \n",
    "    end_time = time.time()   \n",
    "    desc = f' Elapse_time for \"{pgm}\".' \n",
    "    elapse_time (  start_time, end_time, desc)    \n",
    "    return  test_new_proobs, train_new_proobs, testLevels, testLevelss, trainLevelss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def proc_cr_df(test_size, c_parm, embed_typ, adj_typ):\n",
    "\n",
    "    start_time = time.time()\n",
    "    pgm = inspect.currentframe().f_code.co_name \n",
    "    print(\"---------------------------------------------\\FINAL COUNTS:\\n---------------------------------------------\")\n",
    "    print(\"1)\", len(A_test + A_train))\n",
    "    print(\"2)\", len(['Test']*len(A_test) + ['Train']*len(A_train)))\n",
    "    print(\"3)\", len(B_test + B_train))\n",
    "    print(\"4)\", len(testLevels + B_train))\n",
    "    print(\"5)\", len(testLevelss + trainLevelss))\n",
    "    print(\"6)\", int(len(test_new_proobs + train_new_proobs)))\n",
    "    \n",
    "    data = {\n",
    "        'GTIN' : A_test + A_train,\n",
    "        'Source': ['Test']*len(A_test) + ['Train']*len(A_train),\n",
    "        'Actual l1_l2' : B_test + B_train,\n",
    "        'Actuals' : testLevels + B_train,\n",
    "        'Predictions' : testLevelss + trainLevelss,\n",
    "        'Scores' : test_new_proobs + train_new_proobs,\n",
    "    \n",
    "    }\n",
    "    \n",
    "    df = pd.DataFrame(data)\n",
    "    df = df.merge(pim_gtin_mapped[['GTIN', 'ITM_ID', 'PMY_DPT_CD', 'PMY_DPT_DSC', 'REC_DPT_CD',\n",
    "        'REC_DPT_DSC', 'DPT_CD', 'DPT_DSC', 'COM_CD', 'COM_DSC', 'SUBCOM_CD',\n",
    "        'SUBCOM_DSC', 'VND_ECOM_DSC']], on='GTIN', how='left')\n",
    "    df = df[['ITM_ID', 'GTIN', 'PMY_DPT_CD', 'PMY_DPT_DSC', 'REC_DPT_CD', 'REC_DPT_DSC', 'DPT_CD',\n",
    "        'DPT_DSC', 'COM_CD', 'COM_DSC', 'SUBCOM_CD', 'SUBCOM_DSC',\n",
    "        'VND_ECOM_DSC', 'Source', 'Actual l1_l2', 'Actuals', 'Predictions', 'Scores']]\n",
    "    #filename = 'Syndigo_Mapping_L1_L2_ML.csv'\n",
    "    tab_name = f'{embed_typ}_L1_L2_prd_{adj_typ}'  \n",
    "    #df.to_csv(DBFO + filename, index=False)\n",
    "    #print(f\"{filename}  --file created successfully\")\n",
    "\n",
    "    end_time = time.time()   \n",
    "    desc = f'Elapse_time for \"{pgm}\".' \n",
    "    elapse_time (  start_time, end_time, desc)\n",
    "    return df, tab_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_excel_pred( excel_file, dict):\n",
    "#  Write classification report to excel\n",
    "#  save() is going to remove, use close() instead\n",
    "   from pandas import ExcelWriter\n",
    "   from pandas import ExcelFile\n",
    "   writer = pd.ExcelWriter(excel_file)\n",
    "   for key,  value in dict.items():\n",
    "       df   =  value[0] \n",
    "       tab  =  value[1] \n",
    "       df.to_excel(writer,tab)\n",
    "   writer.close()\n",
    "   return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_excel_metric( excel_file, dict, l_metric):\n",
    "#  Write classification report to excel\n",
    "#  save() is going to remove, use close() instead\n",
    "   from pandas import ExcelWriter\n",
    "   from pandas import ExcelFile\n",
    "   writer = pd.ExcelWriter(excel_file)\n",
    "   for key,  value in dict.items():\n",
    "       df   =  value[0] \n",
    "       tab  =  value[1] \n",
    "       df.to_excel(writer,tab)\n",
    "   df_pred = pd.DataFrame(l_metric, columns = ['embed_typ', 'adj_typ, ''test_size', 'c_parm', 'accuracy', 'f1_score_weighted', 'f1_score_macro',\n",
    "                                                'f1_score_micro', 'elapse_time'] )   \n",
    "   df_pred.to_excel(writer,'Consolidate Metrics')                                         \n",
    "   writer.close()\n",
    "   return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "38b64183-34df-46b6-b1c9-6bbe78776fd9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd, numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV, SGDClassifier,  RidgeClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from gensim.models import Word2Vec, KeyedVectors\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datetime import date\n",
    "\n",
    "\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.metrics import roc_auc_score, f1_score\n",
    "import re, time, inspect, pickle\n",
    "from collections import Counter\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.pipeline import Pipeline\n",
    "from matplotlib import pyplot\n",
    "from numpy import where\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "pd.options.display.float_format = '{:20,.2f}'.format \n",
    "pd.set_option(\"display.max_rows\", None)\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "\n",
    "# load  function of 'elapse_time'\n",
    "path_code = 'C:\\\\users\\\\iny2819\\\\kroger\\\\Code\\\\'  \n",
    "f_com_code = path_code + \"com_code.py\"\n",
    "exec(compile(open(f_com_code , \"rb\").read(), f_com_code, 'exec' ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "DBFS = \"/dbfs/FileStore/tables/OFFSHORE/\"\n",
    "DBFO = \"/dbfs/FileStore/tables/OFFSHORE/\"\n",
    "DBFM = \"/dbfs/FileStore/tables/MALLIK/\"\n",
    "DBFR = \"/dbfs/FileStore/tables/OFFSHORE_RESULTS/\"\n",
    "path = 'C:\\\\users\\\\iny2819\\\\kroger\\\\Data\\\\'   \n",
    "DBFS = path\n",
    "DBFO = path\n",
    "DBFM = path\n",
    "DBFR = path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before drop pim_gtin_mapped.shape (5061471, 24)\n",
      "After drop pim_gtin_mapped.shape (5061471, 24)\n"
     ]
    }
   ],
   "source": [
    "syndigo_mapped, pim_gtin_mapped = prepare_data_1()\n",
    "syndigo_mapped_bkup = syndigo_mapped.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " samp_frac = 0.3\n",
      "Before sample syndigo_mapped.shape (259085, 25)\n",
      "After sample syndigo_mapped.shape (77726, 25)\n",
      "after drop syndigo_mapped.shape (77637, 25)\n",
      "Class=0, n=1327 (1.709%)\n",
      "Class=1, n=5993 (7.719%)\n",
      "Class=2, n=22529 (29.018%)\n",
      "Class=3, n=498 (0.641%)\n",
      "Class=4, n=365 (0.470%)\n",
      "Class=5, n=4020 (5.178%)\n",
      "Class=6, n=2703 (3.482%)\n",
      "Class=7, n=6772 (8.723%)\n",
      "Class=8, n=279 (0.359%)\n",
      "Class=9, n=119 (0.153%)\n",
      "Class=10, n=46 (0.059%)\n",
      "Class=11, n=6485 (8.353%)\n",
      "Class=12, n=1917 (2.469%)\n",
      "Class=13, n=2083 (2.683%)\n",
      "Class=14, n=2744 (3.534%)\n",
      "Class=15, n=14 (0.018%)\n",
      "Class=16, n=254 (0.327%)\n",
      "Class=17, n=323 (0.416%)\n",
      "Class=18, n=1020 (1.314%)\n",
      "Class=19, n=175 (0.225%)\n",
      "Class=20, n=69 (0.089%)\n",
      "Class=21, n=643 (0.828%)\n",
      "Class=22, n=1212 (1.561%)\n",
      "Class=23, n=1674 (2.156%)\n",
      "Class=24, n=335 (0.431%)\n",
      "Class=25, n=1784 (2.298%)\n",
      "Class=26, n=553 (0.712%)\n",
      "Class=27, n=291 (0.375%)\n",
      "Class=28, n=178 (0.229%)\n",
      "Class=29, n=279 (0.359%)\n",
      "Class=30, n=1612 (2.076%)\n",
      "Class=31, n=93 (0.120%)\n",
      "Class=32, n=252 (0.325%)\n",
      "Class=33, n=1499 (1.931%)\n",
      "Class=34, n=113 (0.146%)\n",
      "Class=35, n=160 (0.206%)\n",
      "Class=36, n=106 (0.137%)\n",
      "Class=37, n=124 (0.160%)\n",
      "Class=38, n=491 (0.632%)\n",
      "Class=39, n=277 (0.357%)\n",
      "Class=40, n=333 (0.429%)\n",
      "Class=41, n=252 (0.325%)\n",
      "Class=42, n=1562 (2.012%)\n",
      "Class=43, n=643 (0.828%)\n",
      "Class=44, n=46 (0.059%)\n",
      "Class=45, n=29 (0.037%)\n",
      "Class=46, n=32 (0.041%)\n",
      "Class=47, n=55 (0.071%)\n",
      "Class=48, n=20 (0.026%)\n",
      "Class=49, n=192 (0.247%)\n",
      "Class=50, n=16 (0.021%)\n",
      "Class=51, n=63 (0.081%)\n",
      "Class=52, n=10 (0.013%)\n",
      "Class=53, n=37 (0.048%)\n",
      "Class=54, n=77 (0.099%)\n",
      "Class=55, n=146 (0.188%)\n",
      "Class=56, n=183 (0.236%)\n",
      "Class=57, n=22 (0.028%)\n",
      "Class=58, n=11 (0.014%)\n",
      "Class=59, n=95 (0.122%)\n",
      "Class=60, n=35 (0.045%)\n",
      "Class=61, n=37 (0.048%)\n",
      "Class=62, n=19 (0.024%)\n",
      "Class=63, n=8 (0.010%)\n",
      "Class=64, n=98 (0.126%)\n",
      "Class=65, n=13 (0.017%)\n",
      "Class=66, n=4 (0.005%)\n",
      "Class=67, n=101 (0.130%)\n",
      "Class=68, n=73 (0.094%)\n",
      "Class=69, n=55 (0.071%)\n",
      "Class=70, n=12 (0.015%)\n",
      "Class=71, n=15 (0.019%)\n",
      "Class=72, n=6 (0.008%)\n",
      "Class=73, n=80 (0.103%)\n",
      "Class=74, n=9 (0.012%)\n",
      "Class=75, n=18 (0.023%)\n",
      "Class=76, n=159 (0.205%)\n",
      "Class=77, n=86 (0.111%)\n",
      "Class=78, n=93 (0.120%)\n",
      "Class=79, n=20 (0.026%)\n",
      "Class=80, n=106 (0.137%)\n",
      "Class=81, n=10 (0.013%)\n",
      "Class=82, n=17 (0.022%)\n",
      "Class=83, n=113 (0.146%)\n",
      "Class=84, n=9 (0.012%)\n",
      "Class=85, n=8 (0.010%)\n",
      "Class=86, n=14 (0.018%)\n",
      "Class=87, n=41 (0.053%)\n",
      "Class=88, n=3 (0.004%)\n",
      "Class=89, n=39 (0.050%)\n",
      "Class=90, n=54 (0.070%)\n",
      "Class=91, n=13 (0.017%)\n",
      "Class=92, n=105 (0.135%)\n",
      "Class=93, n=14 (0.018%)\n",
      "Class=94, n=12 (0.015%)\n",
      "Class=95, n=60 (0.077%)\n",
      "Class=96, n=34 (0.044%)\n",
      "Class=97, n=29 (0.037%)\n",
      "Class=98, n=9 (0.012%)\n",
      "Class=99, n=15 (0.019%)\n",
      "Class=100, n=8 (0.010%)\n",
      "Class=101, n=16 (0.021%)\n",
      "Class=102, n=17 (0.022%)\n",
      "Class=103, n=25 (0.032%)\n",
      "Class=104, n=64 (0.082%)\n",
      "Class=105, n=17 (0.022%)\n",
      "Class=106, n=29 (0.037%)\n",
      "Class=107, n=8 (0.010%)\n",
      "Class=108, n=25 (0.032%)\n",
      "Class=109, n=16 (0.021%)\n",
      "Class=110, n=7 (0.009%)\n",
      "Class=111, n=48 (0.062%)\n",
      "Class=112, n=9 (0.012%)\n",
      "Class=113, n=15 (0.019%)\n",
      "Class=114, n=23 (0.030%)\n",
      "Class=115, n=19 (0.024%)\n",
      "Class=116, n=7 (0.009%)\n",
      "Class=117, n=10 (0.013%)\n",
      "Class=118, n=6 (0.008%)\n",
      "Class=119, n=16 (0.021%)\n",
      "Class=120, n=3 (0.004%)\n",
      "Class=121, n=7 (0.009%)\n",
      "Class=122, n=39 (0.050%)\n",
      "Class=123, n=6 (0.008%)\n",
      "Class=124, n=11 (0.014%)\n",
      "Class=125, n=8 (0.010%)\n",
      "Class=126, n=16 (0.021%)\n",
      "Class=127, n=3 (0.004%)\n",
      "Class=128, n=24 (0.031%)\n",
      "Class=129, n=4 (0.005%)\n",
      "Class=130, n=9 (0.012%)\n",
      "Class=131, n=8 (0.010%)\n",
      "Class=132, n=23 (0.030%)\n",
      "Class=133, n=16 (0.021%)\n",
      "Class=134, n=17 (0.022%)\n",
      "Class=135, n=7 (0.009%)\n",
      "Class=136, n=11 (0.014%)\n",
      "Class=137, n=3 (0.004%)\n",
      "Class=138, n=21 (0.027%)\n",
      "Class=139, n=9 (0.012%)\n",
      "Class=140, n=4 (0.005%)\n",
      "Class=141, n=17 (0.022%)\n",
      "Class=142, n=23 (0.030%)\n",
      "Class=143, n=5 (0.006%)\n",
      "Class=144, n=7 (0.009%)\n",
      "Class=145, n=4 (0.005%)\n",
      "Class=146, n=3 (0.004%)\n",
      "Class=147, n=4 (0.005%)\n",
      "Class=148, n=4 (0.005%)\n",
      "Class=149, n=3 (0.004%)\n",
      "Class=150, n=8 (0.010%)\n",
      "Class=151, n=3 (0.004%)\n",
      "Class=152, n=4 (0.005%)\n",
      "Class=153, n=4 (0.005%)\n",
      "Class=154, n=3 (0.004%)\n",
      "Class=155, n=3 (0.004%)\n",
      "Class=156, n=6 (0.008%)\n",
      "Class=157, n=6 (0.008%)\n",
      "Class=158, n=3 (0.004%)\n",
      "Class=159, n=6 (0.008%)\n",
      "Class=160, n=3 (0.004%)\n",
      "Class=161, n=3 (0.004%)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Elapse_time for \"prepare_data_2\". It took 4.144443 seconds - 0hh:0mm:4ss.\n",
      " start time: Sep 07 2023 22:16:20  end time:  Sep 07 2023 22:16:25\n",
      "Build model for adj_typ smote; len  of y_train = 2554740, len  of B_train = 2554740\n",
      "Training starts for test_size = 0.3, c_parm = 100 \n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 3.08 GiB for an array with shape (2554740, 162) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"C:\\Users\\iny2819\\AppData\\Roaming\\Python\\Python310\\site-packages\\joblib\\_parallel_backends.py\", line 273, in _wrap_func_call\n    return func()\n  File \"C:\\Users\\iny2819\\AppData\\Roaming\\Python\\Python310\\site-packages\\joblib\\parallel.py\", line 589, in __call__\n    return [func(*args, **kwargs)\n  File \"C:\\Users\\iny2819\\AppData\\Roaming\\Python\\Python310\\site-packages\\joblib\\parallel.py\", line 589, in <listcomp>\n    return [func(*args, **kwargs)\n  File \"C:\\Users\\iny2819\\AppData\\Local\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py\", line 123, in __call__\n    return self.function(*args, **kwargs)\n  File \"C:\\Users\\iny2819\\AppData\\Local\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 524, in _logistic_regression_path\n    w0, n_iter_i, warm_start_sag = sag_solver(\n  File \"C:\\Users\\iny2819\\AppData\\Local\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py\", line 288, in sag_solver\n    gradient_memory_init = np.zeros(\nnumpy.core._exceptions._ArrayMemoryError: Unable to allocate 3.08 GiB for an array with shape (2554740, 162) and data type float64\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[45], line 22\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m adj_typ \u001b[38;5;129;01min\u001b[39;00m l_adj_typ:\n\u001b[0;32m     20\u001b[0m     start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()  \n\u001b[1;32m---> 22\u001b[0m     preds, preds_lrtf, probs, preds_train, probs_train, lr_tf \u001b[38;5;241m=\u001b[39m \u001b[43mproc_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc_parm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membed_typ\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madj_typ\u001b[49m\u001b[43m)\u001b[49m  \n\u001b[0;32m     23\u001b[0m     test_metrics, vtab, l_metrics  \u001b[38;5;241m=\u001b[39m  validation(test_size, c_parm, embed_typ, adj_typ) \n\u001b[0;32m     24\u001b[0m     key \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest_metric\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(i)\n",
      "Cell \u001b[1;32mIn[39], line 29\u001b[0m, in \u001b[0;36mproc_predict\u001b[1;34m(test_size, c_parm, embed_typ, adj_typ)\u001b[0m\n\u001b[0;32m     26\u001b[0m lr_tf \u001b[38;5;241m=\u001b[39m LogisticRegression(C \u001b[38;5;241m=\u001b[39m c_parm, multi_class \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmultinomial\u001b[39m\u001b[38;5;124m'\u001b[39m, solver \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msaga\u001b[39m\u001b[38;5;124m'\u001b[39m, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining starts for test_size = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_size\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, c_parm = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mc_parm\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 29\u001b[0m \u001b[43mlr_tf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     30\u001b[0m preds \u001b[38;5;241m=\u001b[39m lr_tf\u001b[38;5;241m.\u001b[39mpredict(X_test)\n\u001b[0;32m     31\u001b[0m \u001b[38;5;66;03m#print(f\"type(preds) {type(preds)} len(preds) {len(preds)} \\n preds[0:10] {preds[0:10]}\")\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1291\u001b[0m, in \u001b[0;36mLogisticRegression.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1288\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1289\u001b[0m     n_threads \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m-> 1291\u001b[0m fold_coefs_ \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprefer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprefer\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1292\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath_func\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1293\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1294\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1295\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpos_class\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclass_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1296\u001b[0m \u001b[43m        \u001b[49m\u001b[43mCs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mC_\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1297\u001b[0m \u001b[43m        \u001b[49m\u001b[43ml1_ratio\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43ml1_ratio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1298\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfit_intercept\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_intercept\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1299\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1300\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1301\u001b[0m \u001b[43m        \u001b[49m\u001b[43msolver\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msolver\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1302\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmulti_class\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmulti_class\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1303\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_iter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1304\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1305\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1306\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1307\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcoef\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwarm_start_coef_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1308\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpenalty\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpenalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1309\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_squared_sum\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_squared_sum\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1310\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1311\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_threads\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_threads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1312\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1313\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mclass_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwarm_start_coef_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mclasses_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwarm_start_coef\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1314\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1316\u001b[0m fold_coefs_, _, n_iter_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mfold_coefs_)\n\u001b[0;32m   1317\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_iter_ \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(n_iter_, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mint32)[:, \u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:63\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     58\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     59\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     61\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     62\u001b[0m )\n\u001b[1;32m---> 63\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\joblib\\parallel.py:1952\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1946\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[0;32m   1947\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[0;32m   1948\u001b[0m \u001b[38;5;66;03m# reach the first `yield` statement. This starts the aynchronous\u001b[39;00m\n\u001b[0;32m   1949\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[0;32m   1950\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 1952\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\joblib\\parallel.py:1595\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[1;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[0;32m   1592\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[0;32m   1594\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1595\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[0;32m   1597\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[0;32m   1598\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[0;32m   1599\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[0;32m   1600\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[0;32m   1601\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\joblib\\parallel.py:1699\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1692\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wait_retrieval():\n\u001b[0;32m   1693\u001b[0m \n\u001b[0;32m   1694\u001b[0m     \u001b[38;5;66;03m# If the callback thread of a worker has signaled that its task\u001b[39;00m\n\u001b[0;32m   1695\u001b[0m     \u001b[38;5;66;03m# triggered an exception, or if the retrieval loop has raised an\u001b[39;00m\n\u001b[0;32m   1696\u001b[0m     \u001b[38;5;66;03m# exception (e.g. `GeneratorExit`), exit the loop and surface the\u001b[39;00m\n\u001b[0;32m   1697\u001b[0m     \u001b[38;5;66;03m# worker traceback.\u001b[39;00m\n\u001b[0;32m   1698\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_aborting:\n\u001b[1;32m-> 1699\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_error_fast\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1700\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m   1702\u001b[0m     \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[0;32m   1703\u001b[0m     \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\joblib\\parallel.py:1734\u001b[0m, in \u001b[0;36mParallel._raise_error_fast\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1730\u001b[0m \u001b[38;5;66;03m# If this error job exists, immediatly raise the error by\u001b[39;00m\n\u001b[0;32m   1731\u001b[0m \u001b[38;5;66;03m# calling get_result. This job might not exists if abort has been\u001b[39;00m\n\u001b[0;32m   1732\u001b[0m \u001b[38;5;66;03m# called directly or if the generator is gc'ed.\u001b[39;00m\n\u001b[0;32m   1733\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m error_job \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1734\u001b[0m     \u001b[43merror_job\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_result\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\joblib\\parallel.py:736\u001b[0m, in \u001b[0;36mBatchCompletionCallBack.get_result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    730\u001b[0m backend \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparallel\u001b[38;5;241m.\u001b[39m_backend\n\u001b[0;32m    732\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m backend\u001b[38;5;241m.\u001b[39msupports_retrieve_callback:\n\u001b[0;32m    733\u001b[0m     \u001b[38;5;66;03m# We assume that the result has already been retrieved by the\u001b[39;00m\n\u001b[0;32m    734\u001b[0m     \u001b[38;5;66;03m# callback thread, and is stored internally. It's just waiting to\u001b[39;00m\n\u001b[0;32m    735\u001b[0m     \u001b[38;5;66;03m# be returned.\u001b[39;00m\n\u001b[1;32m--> 736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_return_or_raise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    738\u001b[0m \u001b[38;5;66;03m# For other backends, the main thread needs to run the retrieval step.\u001b[39;00m\n\u001b[0;32m    739\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\joblib\\parallel.py:754\u001b[0m, in \u001b[0;36mBatchCompletionCallBack._return_or_raise\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    752\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    753\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m==\u001b[39m TASK_ERROR:\n\u001b[1;32m--> 754\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\n\u001b[0;32m    755\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\n\u001b[0;32m    756\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 3.08 GiB for an array with shape (2554740, 162) and data type float64"
     ]
    }
   ],
   "source": [
    "l_c_parm = [0.1, 1, 10, 100] \n",
    "c_parm = 100 \n",
    "l_embed_typ = ['tfidf', 'W2vec']\n",
    "\n",
    "embed_typ = 'W2vec'\n",
    "l_adj_typ= ['no_smote', 'smote', 'smote_under']\n",
    "l_adj_typ= ['smote', 'smote_under']\n",
    "\n",
    "dic_metric={}\n",
    "dic_predict = {}\n",
    "l_metric=[]\n",
    "test_size = 0.3\n",
    "\n",
    "i = 0\n",
    "dte = date.today().strftime('%m%d%y')\n",
    "\n",
    "for embed_typ in l_embed_typ:\n",
    "    X, y, l1_l2_id_map, id_l1_l2_map = prepare_data_2(samp_frac = 0.3, embed_typ = embed_typ )\n",
    "    for adj_typ in l_adj_typ:\n",
    "        start_time = time.time()  \n",
    "        \n",
    "        preds, preds_lrtf, probs, preds_train, probs_train, lr_tf = proc_predict(test_size, c_parm, embed_typ, adj_typ)  \n",
    "        test_metrics, vtab, l_metrics  =  validation(test_size, c_parm, embed_typ, adj_typ) \n",
    "        key = 'test_metric' + str(i)\n",
    "        dic_metric [key] = (test_metrics, vtab)\n",
    "        \n",
    "        test_new_proobs, train_new_proobs, testLevels, testLevelss, trainLevelss = proc_append()\n",
    "        df_save, ftab  = proc_cr_df(test_size, c_parm, embed_typ, adj_typ )\n",
    "        key = 'predict'+ str(i)\n",
    "        dic_predict[key] = (df_save, ftab)\n",
    "        i = i + 1   \n",
    "        end_time = time.time() \n",
    "        desc = f' Elapse_time to build model for for test_size = 0.3, c_parm = {c_parm}, embed_typ= {embed_typ}' \n",
    "        hh, mm, ss= elapse_time (  start_time, end_time, desc)\n",
    "                                 \n",
    "        l_metrics = l_metrics +  [f\"{hh:2d}hh:{mm:2d}mm:{ss:2d}ss\"]   \n",
    "        l_metric.append(l_metrics)\n",
    "                                  \n",
    "excel_file = DBFO + f'L1_L2_syndigo_pred_cls_rpt_{adj_typ}_{dte}.xlsx'\n",
    "save_excel_metric( excel_file, dic_metric, l_metric)\n",
    "\n",
    "\n",
    "excel_file = DBFO + f'L1_L2_syndigo_pred_{adj_typ}_{dte}.xlsx'\n",
    "save_excel_pred( excel_file, dic_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(A_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2554740"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = Counter(y)\n",
    "for k,v in counter.items():\n",
    "\tper = v / len(y) * 100\n",
    "\tprint('Class=%d, n=%d (%.3f%%)' % (k, v, per))\n",
    "# plot the distribution\n",
    "pyplot.bar(counter.keys(), counter.values())\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidParameterError",
     "evalue": "The 'k_neighbors' parameter of SMOTE must be an int in the range [1, inf) or an object implementing 'kneighbors' and 'kneighbors_graph'. Got 0 instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidParameterError\u001b[0m                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 5\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# ValueError: Expected n_neighbors <= n_samples,  but n_samples = 4, n_neighbors = 6\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# oversample = SMOTE(k_neighbors = 2) - Expected n_neighbors <= n_samples,  but n_samples = 2, n_neighbors = 3\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m#  k_neighbors <= 2 NW) will get k_neighbors not defined\u001b[39;00m\n\u001b[0;32m      4\u001b[0m oversample \u001b[38;5;241m=\u001b[39m SMOTE(k_neighbors \u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m) \u001b[38;5;66;03m# remove count < 3 from y \u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m X1, y1 \u001b[38;5;241m=\u001b[39m \u001b[43moversample\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_resample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\lib\\site-packages\\imblearn\\base.py:202\u001b[0m, in \u001b[0;36mBaseSampler.fit_resample\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    181\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit_resample\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y):\n\u001b[0;32m    182\u001b[0m     \u001b[38;5;124;03m\"\"\"Resample the dataset.\u001b[39;00m\n\u001b[0;32m    183\u001b[0m \n\u001b[0;32m    184\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    200\u001b[0m \u001b[38;5;124;03m        The corresponding label of `X_resampled`.\u001b[39;00m\n\u001b[0;32m    201\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 202\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_params\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    203\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mfit_resample(X, y)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\lib\\site-packages\\sklearn\\base.py:581\u001b[0m, in \u001b[0;36mBaseEstimator._validate_params\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    573\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_validate_params\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    574\u001b[0m     \u001b[38;5;124;03m\"\"\"Validate types and values of constructor parameters\u001b[39;00m\n\u001b[0;32m    575\u001b[0m \n\u001b[0;32m    576\u001b[0m \u001b[38;5;124;03m    The expected type and values must be defined in the `_parameter_constraints`\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    579\u001b[0m \u001b[38;5;124;03m    accepted constraints.\u001b[39;00m\n\u001b[0;32m    580\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 581\u001b[0m     \u001b[43mvalidate_parameter_constraints\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    582\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parameter_constraints\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    583\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_params\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdeep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    584\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcaller_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__class__\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__name__\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    585\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\lib\\site-packages\\sklearn\\utils\\_param_validation.py:97\u001b[0m, in \u001b[0;36mvalidate_parameter_constraints\u001b[1;34m(parameter_constraints, params, caller_name)\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     92\u001b[0m     constraints_str \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     93\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([\u001b[38;5;28mstr\u001b[39m(c) \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m constraints[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m or\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     94\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconstraints[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     95\u001b[0m     )\n\u001b[1;32m---> 97\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m InvalidParameterError(\n\u001b[0;32m     98\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparam_name\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m parameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcaller_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     99\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconstraints_str\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparam_val\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    100\u001b[0m )\n",
      "\u001b[1;31mInvalidParameterError\u001b[0m: The 'k_neighbors' parameter of SMOTE must be an int in the range [1, inf) or an object implementing 'kneighbors' and 'kneighbors_graph'. Got 0 instead."
     ]
    }
   ],
   "source": [
    "# ValueError: Expected n_neighbors <= n_samples,  but n_samples = 4, n_neighbors = 6\n",
    "# oversample = SMOTE(k_neighbors = 2) - Expected n_neighbors <= n_samples,  but n_samples = 2, n_neighbors = 3\n",
    "#  k_neighbors <= 2 NW) will get k_neighbors not defined\n",
    "oversample = SMOTE(k_neighbors =0) # remove count < 3 from y \n",
    "X1, y1 = oversample.fit_resample(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ValueError: \"sampling_strategy\" can be a float only when the type of target is binary. For multi-class, use a dict.\n",
    "from imblearn.pipeline import Pipeline# ValueError: Expected n_neighbors <= n_samples,  but n_samples = 4, n_neighbors = 6\n",
    "# oversample = SMOTE(k_neighbors = 2) - Expected n_neighbors <= n_samples,  but n_samples = 2, n_neighbors = 3\n",
    "#  k_neighbors <= 2 NW) will get k_neighbors not defined\n",
    "oversample = SMOTE(k_neighbors =2) # remove count < 3 from y \n",
    "X1, y1 = oversample.fit_resample(X, y)\n",
    "#over = SMOTE(sampling_strategy=0.1)\n",
    "#under = RandomUnderSampler(sampling_strategy=0.5)\n",
    "over = SMOTE(k_neighbors = 2)\n",
    "under = RandomUnderSampler()\n",
    "steps = [('o', over), ('u', under)]\n",
    "pipeline = Pipeline(steps=steps)\n",
    "# transform the dataset\n",
    "X2, y2 = pipeline.fit_resample(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# oversample - = SMOTE(k_neighbors =3)  -ValueError: Expected n_neighbors <= n_samples,  but n_samples = 3, n_neighbors = 4\n",
    "# oversample = SMOTE(k_neighbors = 2) - Expected n_neighbors <= n_samples,  but n_samples = 2, n_neighbors = 3\n",
    "#  k_neighbors <= 2 NW) will get k_neighbors not defined\n",
    "oversample = SMOTE(k_neighbors =1) # remove count < 3 from y \n",
    "X3, y3 = oversample.fit_resample(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate a model\n",
    "def evaluate_model(X, y, model):\n",
    " # define evaluation procedure\n",
    " cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=3, random_state=1)\n",
    " # evaluate model\n",
    " #scores = cross_val_score(model, X, y, scoring='roc_auc', cv=cv, n_jobs=-1)\n",
    " scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    " return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model - numpy.core._exceptions._ArrayMemoryError: Unable to allocate 61.8 MiB for an array with shape (50000, 162) and data type float64\n",
    "c_parm = 100\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "model = LogisticRegression(C = c_parm, multi_class = 'multinomial', solver = 'saga', n_jobs=-1)\n",
    "#model = RandomForestClassifier(n_estimators=1000, class_weight='balanced')\n",
    "# evaluate the model\n",
    "scores = evaluate_model(X, y, model)\n",
    "# summarize performance\n",
    "print('ROc_AUC: %.3f (%.3f)' % (np.mean(scores), np.std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model\n",
    "c_parm = 100\n",
    "\n",
    "model1 = LogisticRegression(C = c_parm, multi_class = 'multinomial', solver = 'saga', n_jobs=-1)\n",
    "#model = RandomForestClassifier(n_estimators=1000, class_weight='balanced')\n",
    "# evaluate the model\n",
    "scores1 = evaluate_model(X1, y1, model1)\n",
    "# summarize performance\n",
    "print('ROc_AUC: %.3f (%.3f)' % (np.mean(scores1), np.std(scores1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = LogisticRegression(C = c_parm, multi_class = 'multinomial', solver = 'saga', n_jobs=-1)\n",
    "#model = RandomForestClassifier(n_estimators=1000, class_weight='balanced')\n",
    "# evaluate the model\n",
    "scores3 = evaluate_model(X3, y3, model3)\n",
    "# summarize performance\n",
    "print('ROc_AUC: %.3f (%.3f)' % (np.mean(scores2), np.std(scores2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = LogisticRegression(C = c_parm, multi_class = 'multinomial', solver = 'saga', n_jobs=-1)\n",
    "#model = RandomForestClassifier(n_estimators=1000, class_weight='balanced')\n",
    "# evaluate the model\n",
    "scores2 = evaluate_model(X2, y2, model2)\n",
    "# summarize performance\n",
    "print('ROc_AUC: %.3f (%.3f)' % (np.mean(scores2), np.std(scores2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('ROc_AUC: %.3f (%.3f)' % (np.mean(scores), np.std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# NW\n",
    "for label, _ in counter.items():\n",
    " row_ix = where(y == label)[0]\n",
    " pyplot.scatter(X[row_ix, 0], X[row_ix, 1], label=str(label))\n",
    "pyplot.legend()\n",
    "pyplot.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "excel_file = DBFO + f'L1_L2_syndigo_pred_tst_size{test_size}_082527.xlsx'\n",
    "save_excel( excel_file, dic_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic_predict.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size = 0.3 \n",
    "excel_file = DBFO + f'L1_L2_syndigo_pred_cls_rpt_size{test_size}_082527.xlsx'\n",
    "save_excel_metric( excel_file, dic_metric, l_metric)\n",
    "\n",
    "\n",
    "excel_file = DBFO + f'L1_L2_syndigo_pred_tst_size{test_size}_082527.xlsx'\n",
    "save_excel_pred( excel_file, dic_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_class = 'multinomial'\n",
    "score = roc_auc_score(y_test, preds, multi_class= multi_class)\n",
    "print(f\"ROC AUC score for Multiclass= {multi_class}: {score:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pim_gtin_mapped.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pim_gtin_mapped.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pim_gtin_mapped['ITM_ID_y'].value_counts(dropna = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "4823143/len(pim_gtin_mapped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "type(l1_l2_id_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dict = pd.DataFrame.from_dict(id_l1_l2_map, orient ='index', columns=['l1_l2']) \n",
    "df_dict.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dict = df_dict.rename_axis('value').reset_index()\n",
    "df_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_dict = pd.DataFrame.from_dict(id_l1_l2_map, orient ='index', columns=['l1_l2']).reset_index() \n",
    "df_dict.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'C:\\\\users\\\\iny2819\\\\kroger\\\\Data\\\\'\n",
    "df_dict.to_csv(path + \"id_l1_l2_map.csv\", index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dict_1 = pd.DataFrame.from_dict(id_l1_l2_map)  #  If using all scalar values, you must pass an index\n",
    "df_dict_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1_l2_id_map.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y.value_counts(dropna = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f' Count for y before smote {y.value_counts(dropna = False).sort_index()}') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "77637"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y)    # 77637\n",
    "#len(y1)  # 3649698\n",
    "#len(y2)  # 3649698"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "scipy.sparse._csr.csr_matrix"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_train) \n",
    "#z = pd.Series(list(filter (lambda z: y_list.count(z) > 1, y_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series = syndigo_mapped[syndigo_mapped['l1_l2'].value_counts(ascending=True)\n",
    "if series.tolist():\n",
    "    subset_df = syndigo_mappeddrop(subset_df[subset_df['Level 2'].isin(series[series==1].index.tolist())].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "syndigo_mapped.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len('W2vec_L1_L2_smote_under')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "syndigo_mapped['COM_DSC'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series = syndigo_mapped['l1_l2'].value_counts(ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series = syndigo_mapped[syndigo_mapped['COM_DSC']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "6      74863\n",
    "1      22727\n",
    "12     21240\n",
    "5      19935\n",
    "20     13582\n",
    "0       9018\n",
    "2       8928\n",
    "25      7114\n",
    "15      6296\n",
    "3       6123\n",
    "7       5729\n",
    "21      5333\n",
    "19      5048\n",
    "9       4940\n",
    "14      4483\n",
    "13      3976\n",
    "30      3557\n",
    "41      2150\n",
    "17      2082\n",
    "10      1772\n",
    "44      1649\n",
    "32      1623\n",
    "24      1232\n",
    "11      1224\n",
    "72      1157\n",
    "23      1139\n",
    "27       964\n",
    "34       950\n",
    "29       937\n",
    "99       925\n",
    "4        875\n",
    "22       863\n",
    "35       843\n",
    "38       651\n",
    "53       589\n",
    "42       574\n",
    "87       559\n",
    "50       559\n",
    "16       540\n",
    "18       505\n",
    "83       416\n",
    "48       407\n",
    "63       394\n",
    "69       384\n",
    "52       372\n",
    "58       370\n",
    "84       347\n",
    "28       328\n",
    "33       312\n",
    "65       309\n",
    "90       294\n",
    "74       270\n",
    "70       259\n",
    "75       258\n",
    "45       258\n",
    "40       245\n",
    "43       237\n",
    "47       215\n",
    "31       202\n",
    "78       191\n",
    "8        171\n",
    "62       167\n",
    "36       165\n",
    "61       164\n",
    "79       164\n",
    "100      155\n",
    "85       138\n",
    "55       135\n",
    "67       133\n",
    "37       132\n",
    "49       113\n",
    "73       111\n",
    "114      110\n",
    "76       109\n",
    "46       108\n",
    "121      106\n",
    "88       103\n",
    "57        99\n",
    "80        98\n",
    "105       97\n",
    "96        95\n",
    "60        87\n",
    "77        84\n",
    "113       82\n",
    "81        81\n",
    "39        80\n",
    "134       76\n",
    "26        73\n",
    "120       73\n",
    "106       72\n",
    "66        69\n",
    "148       67\n",
    "86        65\n",
    "169       63\n",
    "158       61\n",
    "139       58\n",
    "123       55\n",
    "122       49\n",
    "108       48\n",
    "64        48\n",
    "93        48\n",
    "117       46\n",
    "149       45\n",
    "110       45\n",
    "143       45\n",
    "151       42\n",
    "92        42\n",
    "115       41\n",
    "125       40\n",
    "56        38\n",
    "51        38\n",
    "129       36\n",
    "109       35\n",
    "130       33\n",
    "59        31\n",
    "103       29\n",
    "112       29\n",
    "177       29\n",
    "176       29\n",
    "172       28\n",
    "128       27\n",
    "89        27\n",
    "116       26\n",
    "173       26\n",
    "54        26\n",
    "107       25\n",
    "136       24\n",
    "111       23\n",
    "168       23\n",
    "102       23\n",
    "181       23\n",
    "126       22\n",
    "153       22\n",
    "159       22\n",
    "178       22\n",
    "199       21\n",
    "124       20\n",
    "167       19\n",
    "187       17\n",
    "118       17\n",
    "94        16\n",
    "137       15\n",
    "179       14\n",
    "171       14\n",
    "221       14\n",
    "150       13\n",
    "97        13\n",
    "200       13\n",
    "101       12\n",
    "156       12\n",
    "180       12\n",
    "204       12\n",
    "135       12\n",
    "104       11\n",
    "160       11\n",
    "207       10\n",
    "227       10\n",
    "170        9\n",
    "163        9\n",
    "259        9\n",
    "183        8\n",
    "95         8\n",
    "98         8\n",
    "161        8\n",
    "132        8\n",
    "71         7\n",
    "185        7\n",
    "234        7\n",
    "249        7\n",
    "202        7\n",
    "253        7\n",
    "154        6\n",
    "236        6\n",
    "232        6\n",
    "188        6\n",
    "175        6\n",
    "142        6\n",
    "141        6\n",
    "165        6\n",
    "82         6\n",
    "205        6\n",
    "194        5\n",
    "131        5\n",
    "196        5\n",
    "144        5\n",
    "174        5\n",
    "233        5\n",
    "155        5\n",
    "157        5\n",
    "166        5\n",
    "229        4\n",
    "230        4\n",
    "201        4\n",
    "218        4\n",
    "214        4\n",
    "208        4\n",
    "231        4\n",
    "206        4\n",
    "182        4\n",
    "195        4\n",
    "192        4\n",
    "162        3\n",
    "210        3\n",
    "262        3\n",
    "186        3\n",
    "133        3\n",
    "217        3\n",
    "216        3\n",
    "152        3\n",
    "225        3\n",
    "266        3\n",
    "245        3\n",
    "197        3\n",
    "270        3\n",
    "256        2\n",
    "239        2\n",
    "241        2\n",
    "235        2\n",
    "147        2\n",
    "242        2\n",
    "255        2\n",
    "228        2\n",
    "164        2\n",
    "91         2\n",
    "252        2\n",
    "271        2\n",
    "212        2\n",
    "189        2\n",
    "269        2\n",
    "268        2\n",
    "193        2\n",
    "119        2\n",
    "191        2\n",
    "261        1\n",
    "251        1\n",
    "254        1\n",
    "250        1\n",
    "267        1\n",
    "257        1\n",
    "273        1\n",
    "258        1\n",
    "265        1\n",
    "272        1\n",
    "264        1\n",
    "277        1\n",
    "276        1\n",
    "275        1\n",
    "274        1\n",
    "263        1\n",
    "260        1\n",
    "220        1\n",
    "248        1\n",
    "247        1\n",
    "146        1\n",
    "145        1\n",
    "140        1\n",
    "138        1\n",
    "184        1\n",
    "190        1\n",
    "198        1\n",
    "127        1\n",
    "68         1\n",
    "203        1\n",
    "209        1\n",
    "211        1\n",
    "213        1\n",
    "215        1\n",
    "219        1\n",
    "222        1\n",
    "223        1\n",
    "224        1\n",
    "226        1\n",
    "237        1\n",
    "238        1\n",
    "240        1\n",
    "243        1\n",
    "244        1\n",
    "246        1\n",
    "278        1"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Syndigo Mapping MachineLearning",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
